[{"content":"Automating your infrastructure with Ansible can be a game-changer for any organization looking to streamline their processes and reduce manual labor.\nAnsible is an open-source automation tool that allows you to automate tasks such as configuration management, application deployment, and orchestration of infrastructure resources, using a declarative language to describe the desired state of a system.\nOne of the key benefits of Ansible is its simplicity and ease of use.\nHere\u0026rsquo;s a quick overview from Fireship.io.\nComponents Inventory An Ansible inventory file is a configuration file that contains a list of hosts and groups that Ansible can manage. The inventory file specifies the target hosts that Ansible should execute tasks against, and can be used to define host-specific variables and group-specific variables.\nAn inventory file is written in INI or YAML format, and can include the following information:\nHostnames or IP addresses of target hosts Connection parameters such as the SSH username, SSH port, or WinRM settings Group definitions, which allow hosts to be grouped together and managed collectively Variables, which can be assigned to individual hosts or groups For example, an inventory file might look like this:\n1 2 3 4 5 6 7 8 9 10 [webservers] web1.example.com web2.example.com [databases] db1.example.com db2.example.com [all:vars] ansible_user=ubuntu Playbooks An Ansible playbook is a set of instructions that define the desired state of a system, and the steps required to achieve that state.\nPlaybooks are also written in YAML format.\nA typical playbook consists of one or more \u0026ldquo;plays\u0026rdquo;, each of which specifies a set of tasks to be executed on a target host or group of hosts.\nEach task defines a set of actions to be performed, such as installing a package, editing a configuration file, or executing a command.\nTasks are executed in a sequential order by utilizing the declarative syntax in YAML to determine the order of execution and the dependencies between tasks.\nPlaybooks can also include variables, which can be used to define reusable values or parameters that can be passed between tasks or plays.\nFor example, here is a playbook which checks for updates on a remote Ubuntu host:\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 --- - name: Check for updates on Ubuntu hosts: 192.168.2.100 become: true tasks: - name: Update apt cache apt: update_cache: yes - name: Check for updates apt: upgrade: dist update_cache: yes Getting Started Windows Ansible can be installed on Windows using Windows Subsystem for Linux (WSL) or a virtual machine (VM).\nIf you don\u0026rsquo;t already use WSL, follow the instructions on Microsoft\u0026rsquo;s website on setting up a WSL machine. Install a Linux distribution such as Ubuntu or Debian from the Microsoft Store, or use this guide. Once you have your Linux machine up and running, run: 1 2 sudo apt update sudo apt install ansible -y Mac OS If you are using Mac OS, you can use Homebrew, a popular package manager for Mac OS.\n1 brew install ansible Ubuntu/Debian-based If you are on Ubuntu, or any Debian-based system, you can use the apt package manager.\n1 2 sudo apt update sudo apt install ansible -y Verify Ansible is installed and working:\n1 ansible --version 1 2 3 4 5 6 7 8 9 ansible [core 2.11.4] config file = None configured module search path = [\u0026#39;/home/devops/.ansible/plugins/modules\u0026#39;, \u0026#39;/usr/share/ansible/plugins/modules\u0026#39;] ansible python module location = /usr/share/lib64/python3.6/site-packages/ansible ansible collection location = /home/devops/.ansible/collections:/usr/share/ansible/collections executable location = /home/devops/.local/bin/ansible python version = 3.6.12 (default, Sep 15 2020, 12:49:50) [GCC 4.8.5 20150623 (Red Hat 4.8.5-37)] jinja version = 2.11.3 libyaml = True SSH Keys Make sure you have access to your hosts with ssh keys.\nYou can generate a key-pair with:\n1 ssh-keygen Then you can copy the keys to the control node with:\n1 ssh-copy-id username@remote_host If you need more information, check out this short guide.\nSetup Inventory File You can start by creating an inventory file that lists the IP addresses or hostnames of the machines you want to manage, keep in mind this can be done in both INI or YAML format.\nIn this case, we\u0026rsquo;ll create one in an .ini file.\ninventory.ini\n1 2 3 [webservers] 192.168.2.100 192.168.2.101 Playbook Then create your playbook file to \u0026ldquo;describe\u0026rdquo; the desired state of your infrastructure.\nplaybook.yml\n1 2 3 4 5 6 7 8 --- - hosts: webservers become: true tasks: - name: Install Apache web server apt: name: apache2 state: present Run the playbook by using ansible-playbook -i \u0026lt;inventory\u0026gt; \u0026lt;playbook\u0026gt;. 1 ansible-playbook -i inventory.ini playbook.yml This will run the playbook and configure the machines listed in the inventory file.\nPractical Uses Provisioning Multiple Servers You can create a playbook that defines the desired configuration for any number of new servers defined in your inventory file, and run it to deploy them automatically without the need for manual configuration, which definitely saves you time, and reduces the likeliness of errors.\nDeploying Applications Ansible can also be used to deploy applications automatically across a variety of hosts.\nApache Example For example, we can setup a simple Apache server to run on a given host in our inventory. This can further be extended if we need to run this on multiple hosts in our inventory file.\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 --- - name: quick-apache-1 hosts: 192.168.2.100 become: true tasks: - name: Update apt cache apt: update_cache: yes - name: Install Apache2 package apt: name: apache2 state: present - name: Enable Apache2 service service: name: apache2 enabled: yes state: started - name: Create index.html file copy: content: \u0026#34;Hello, world!\u0026#34; dest: /var/www/html/index.html The above playbook should setup an Apache web server on host 192.168.2.100.\nAnsible will let us know when the playbook has been completed and report back a status update like below:\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 PLAY [quick-apache-1] **************************************************************** TASK [Gathering Facts] *************************************************************** ok: [192.168.2.100] TASK [Update apt cache] *************************************************************** changed: [192.168.2.100] TASK [Install Apache2 package] ******************************************************** changed: [192.168.2.100] TASK [Enable Apache2 service] ********************************************************* changed: [192.168.2.100] TASK [Create index.html file] ********************************************************* changed: [192.168.2.100] PLAY RECAP **************************************************************************** 192.168.2.100 : ok=5 changed=4 unreachable=0 failed=0 skipped=0 rescued=0 ignored=0 Managing Network Devices Ansible can also be used to manage network devices, such as switches and routers.\nYou can create a playbook that defines the desired configuration for your network devices.\nThis makes it easy to manage your network infrastructure and ensures consistency across your devices.\nManaging Edgerouter X Firewall Rules For example, we can modify firewall rules and manage our Edgerouter X from a playbook file.\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 --- - name: Configure EdgeRouter X firewall hosts: 192.168.2.1 gather_facts: no become: true vars: firewall_rules: - rule_number: 10 action: accept protocol: tcp destination_port: 22 - rule_number: 20 action: accept protocol: tcp destination_port: 80 - rule_number: 30 action: accept protocol: tcp destination_port: 443 - rule_number: 40 action: drop protocol: all source: 192.168.2.0/24 state: new tasks: - name: Add firewall rules edgemax_firewall: rule_number: \u0026#34;{{ item.rule_number }}\u0026#34; action: \u0026#34;{{ item.action }}\u0026#34; protocol: \u0026#34;{{ item.protocol }}\u0026#34; destination_port: \u0026#34;{{ item.destination_port }}\u0026#34; source: \u0026#34;{{ item.source | default(omit) }}\u0026#34; state: \u0026#34;{{ item.state | default(omit) }}\u0026#34; with_items: \u0026#34;{{ firewall_rules }}\u0026#34; Conclusion In conclusion, automating your infrastructure with Ansible can save time, reduce errors, and make your life easier.\nYou can easily provision new servers, deploy applications, and manage your network devices all from within a file.\nLearn More If you wish to learn more, make sure to check out the official documentation, and the community\u0026rsquo;s self-paced lab training.\n","permalink":"https://netsparse.dev/posts/2023-04/automate-your-infrastructure-with-ansible/","summary":"Automating your infrastructure with Ansible can be a game-changer for any organization looking to streamline their processes and reduce manual labor.\nAnsible is an open-source automation tool that allows you to automate tasks such as configuration management, application deployment, and orchestration of infrastructure resources, using a declarative language to describe the desired state of a system.\nOne of the key benefits of Ansible is its simplicity and ease of use.","title":"Automate Your Infrastructure With Ansible"},{"content":"Hugo is a popular static site generator written in Go. It allows you to create and manage static websites quickly and easily.\nIn this guide, we will cover the basics of getting started with Hugo.\nHere\u0026rsquo;s a quick overview from Fireship.io.\nGet Started Installation Download the appropriate package for your system.\nWindows Mac OS Linux Content Management Creating a New Site 1 hugo new site \u0026lt;your-site-name\u0026gt; This will create a new Hugo site in a directory named mysite.\nCreating a New Page 1 hugo new page/about.md This will create a new Markdown file named about.md in the content/page directory.\nAdding Content To add content to your site, open the Markdown file you created in the previous step and add your content using Markdown syntax.\nFor example, to add a heading, use the # character followed by your heading text:\n1 2 3 # About Us Lorem ipsum dolor sit amet, consectetur adipiscing elit, sed do eiusmod tempor incididunt ut labore et dolore magna aliqua. Building Your Site To build your site, navigate to the root directory of your site and run the following command:\n1 hugo serve This will generate your site in a directory named public\nViewing Your Site To view your site, open a web browser and navigate to http://localhost:1313\nTheming If you wish to make your site look awesome or more polished, make sure to check out the Hugo community themes at https://themes.gohugo.io/.\nDeployment \u0026amp; Hosting Once you have tested your site, the final step is to deploy it.\nThere are several options for deploying your Hugo site, including GitHub Pages, Netlify, Cloudflare Pages, Vercel \u0026amp; more.\nWe\u0026rsquo;ll set it up on Netlify as an example, for that we\u0026rsquo;ll need to:\nCreate a new repository on GitHub with the same name as your Hugo site. Push your Hugo site to the new repository using Git. Setup a Netlify account and connect it to the repository in the settings. Choose the branch and folder where your site is located. Wait for the site to be built and deployed. Quick Start Check out Netlify\u0026rsquo;s quick start page to connect your GitHub repo to Netlify and launch your site in under a minute.\nOnce your site is deployed, you can access it using the Netlify-generated URL, which will look something like: https://\u0026lt;random-id\u0026gt;.netlify.app.\nCustom Domains If you own a custom domain, configure your DNS records with your Registrar, and check out how to assign a domain to your site\nConclusion In this guide, we have covered the basics of getting started with Hugo.\nBy using Hugo, you can create and manage static websites quickly and easily, it also provides many features and options for customizing your site, making it a powerful tool for building websites.\nLearn More Check out the official Hugo documentation.\n","permalink":"https://netsparse.dev/posts/2023-04/build-a-quick-website-with-hugo/","summary":"Hugo is a popular static site generator written in Go. It allows you to create and manage static websites quickly and easily.\nIn this guide, we will cover the basics of getting started with Hugo.\nHere\u0026rsquo;s a quick overview from Fireship.io.\nGet Started Installation Download the appropriate package for your system.\nWindows Mac OS Linux Content Management Creating a New Site 1 hugo new site \u0026lt;your-site-name\u0026gt; This will create a new Hugo site in a directory named mysite.","title":"Build a Quick Website With Hugo"},{"content":"I\u0026rsquo;ve been utilizing Jekyll for the past few months to build my website. Although it does a pretty good job at doing so, I\u0026rsquo;ve been taking a look at Hugo and experimenting alongside it.\nI was able to replicate my website on Hugo with a better looking theme and decided to take the leap. I went ahead and migrated my posts and basic items, making sure everything was nicely organized. And so far, it works pretty good!\nI\u0026rsquo;ve went ahead and archived the old site, but still host it with GitHub Pages. If you are curious, it is still accessible here.\nIf you are looking to migrate your Jekyll website to Hugo, fortunately, the migration process from Jekyll to Hugo is relatively straightforward.\nPreparation Install Hugo Download the appropriate package for your system.\nWindows Mac OS Linux Create a New Hugo Site Open your terminal or command prompt and type the following command:\n1 hugo new site \u0026lt;your-site-name\u0026gt; Migration Copy the Content The next step is to copy the content from your Jekyll site to your Hugo site.\nNavigate to the directory of your Jekyll site and copy the following directories:\n1 2 3 _posts/ _layouts/ _includes/ These directories contain your blog posts, page layouts, and includes respectively. Once you have copied these directories, you can paste them into your Hugo site\u0026rsquo;s directory.\nConvert the Front Matter The next step is to convert the front matter of your Jekyll site to the Hugo format.\nThe front matter is the metadata at the beginning of each file that specifies the title, author, date, and other information about the post or page.\nIn Hugo, the front matter is specified in YAML format.\nTo convert the front matter, you need to open each file in your _posts directory and change the front matter to YAML format.\nFor example, if your Jekyll front matter looks like this:\n1 2 3 4 5 --- layout: post title: My First Post date: 2019-01-01 00:00:00 +0000 --- You need to convert the date or other information to the YAML format, it will look very similar, it could pretty much be copied over, you\u0026rsquo;ll just need to modify date:.\n1 2 3 4 5 --- layout: post title: My First Post date: 2019-01-01T00:00:00Z --- Configure the Site The next step is to configure your Hugo site.\nHugo uses a configuration file called config.yml, which contains settings such as the site title, description, and other options.\nIt will look something like this:\n1 2 3 4 baseURL: \u0026#34;/\u0026#34; languageCode: \u0026#34;en-us\u0026#34; title: \u0026#34;My Hugo Site\u0026#34; theme: \u0026#34;my-theme\u0026#34; You can replace the values of these options with your own preferences, as well as define other settings for your site.\nTest the Site Locally The final step is to test your Hugo site. You can do this by running the following command:\n1 hugo serve This will start a local server that you can access in your web browser at http://localhost:1313\nIf everything has been set up correctly, you should see your newly created Hugo site running on the local server.\nDeployment \u0026amp; Hosting Once you have tested your site, the final step is to deploy it.\nThere are several options for deploying your Hugo site, including GitHub Pages, Netlify, Cloudflare Pages, Vercel \u0026amp; more.\nWe\u0026rsquo;ll set it up on Netlify as an example, for that we\u0026rsquo;ll need to:\nCreate a new repository on GitHub with the same name as your Hugo site. Push your Hugo site to the new repository using Git. Setup a Netlify account and connect it to the repository in the settings. Choose the branch and folder where your site is located. Wait for the site to be built and deployed. Quick Start Check out Netlify\u0026rsquo;s quick start page to connect your GitHub repo to Netlify and launch your site in under a minute.\nOnce your site is deployed, you can access it using the Netlify-generated URL, which will look something like: https://\u0026lt;random-id\u0026gt;.netlify.app.\nCustom Domains If you own a custom domain, configure your DNS records with your Registrar, and check out how to assign a domain to your site\nConclusion Migrating your Jekyll website to Hugo is a straightforward process that can be completed in a few steps.\nBy following the steps outlined in this article, you can quickly and easily migrate your website to Hugo and take advantage of its speed, ease of use, and flexibility.\nWhether you are a seasoned web developer or a beginner, Hugo is a great choice for building fast and secure static websites.\nLearn More Learn more about migrating your site to Hugo.\n","permalink":"https://netsparse.dev/posts/2023-04/how-i-migrated-my-site/","summary":"I\u0026rsquo;ve been utilizing Jekyll for the past few months to build my website. Although it does a pretty good job at doing so, I\u0026rsquo;ve been taking a look at Hugo and experimenting alongside it.\nI was able to replicate my website on Hugo with a better looking theme and decided to take the leap. I went ahead and migrated my posts and basic items, making sure everything was nicely organized. And so far, it works pretty good!","title":"Migrating My Site From Jekyll to Hugo"},{"content":"Syncthing is a free, open-source file synchronization software that enables you to synchronize files between your devices securely.\nUnlike traditional cloud-based storage solutions, Syncthing is decentralized, meaning it uses peer-to-peer technology which allow you to sync files between devices without the need for traditional cloud-based storage solutions or SMB/NFS systems.\nIn this article, we will explore how to get started with Syncthing and utilize it to sync some files with our devices.\nGetting Started Syncthing is available for Windows, macOS, Linux, and Android, and can be downloaded here.\nYou will need to extract the .zip file then install from there.\nIf you are on Android or iOS, you can visit the links below:\nAndroid (Play Store) iOS (via Möbius Sync) Note: The iOS client is an unofficial client limited in functionality and features, but will work with files accessible through the Files app on iOS. It also limits you to 20MB of syncing before needing to purchase the \u0026lsquo;Unlimited file sync\u0026rsquo; option. Keep this in mind when deciding to utilize it on iOS. For more info, refer to the FAQ and the company behind the development.\nOnce you have installed Syncthing, you should be able to access the dashboard by opening your web browser and navigating to http://localhost:8384.\nAdding Devices To add a device, you will need to share your device ID with the other device and enter the other device\u0026rsquo;s ID.\nIf you\u0026rsquo;ve setup the other device with Syncthing, you\u0026rsquo;ll likely see the ID, you can then click to auto add the device.\nGo to the Sharing tab, and select the Folder or folders you would like to share from the remote device.\nAdding Folders To add a folder, click on the Add Folder button below the Folders section.\nYou can then select the folder you want to sync, give it an optional Folder Label, from there it will be added and show up on the left side of the dashboard.\nGo to the Sharing tab, and select the Folder you just created. Similar to the picture from above.\nSyncthing will automatically sync the files between them, ensuring that they are always up to date.\nSetting up Syncthing with Docker Docker is a popular tool for managing and deploying applications in containers.\nYou can easily set up a containerized version of Syncthing for a server or central device you would like to store your files on. This is handy if you already implement a NAS system and utilize Docker. It could then be used in conjunction to sync with your other devices.\nDocker Run 1 docker pull syncthing/syncthing 1 2 3 4 docker run -p 8384:8384 -p 22000:22000/tcp -p 22000:22000/udp -p 21027:21027/udp \\ -v /wherever/st-sync:/var/syncthing \\ --hostname=my-syncthing \\ syncthing/syncthing:latest Docker Compose You can also setup syncthing with a docker compose file that they provide, make sure to modify your env variables for your PUID or PGID, as well as your volumes.\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 --- version: \u0026#34;3\u0026#34; services: syncthing: image: syncthing/syncthing container_name: syncthing hostname: my-syncthing environment: - PUID=1000 - PGID=1000 volumes: - /wherever/st-sync:/var/syncthing ports: - 8384:8384 # Web UI - 22000:22000/tcp # TCP file transfers - 22000:22000/udp # QUIC file transfers - 21027:21027/udp # Receive local discovery broadcasts restart: unless-stopped You can then access Syncthing by opening a web browser and navigating to http://localhost:8384.\nFrom here, you can set up your devices and folders just as you would with a non-containerized version of Syncthing.\nMake sure to follow the getting started guide on their website, which should include more detail on how the folders and syncing operates.\nConclusion Syncthing is a powerful tool for synchronizing files between devices securely.\nBy setting up a Syncthing Docker container, you can easily deploy and manage Syncthing on your machine, making it easier to sync files between devices.\nWith Docker, you can quickly spin up and tear down Syncthing containers as needed, making it a flexible and scalable solution for file synchronization.\nLearn More Official Documentation GUI Docker Setup ","permalink":"https://netsparse.dev/posts/2023-03/seamless-file-sync/","summary":"Syncthing is a free, open-source file synchronization software that enables you to synchronize files between your devices securely.\nUnlike traditional cloud-based storage solutions, Syncthing is decentralized, meaning it uses peer-to-peer technology which allow you to sync files between devices without the need for traditional cloud-based storage solutions or SMB/NFS systems.\nIn this article, we will explore how to get started with Syncthing and utilize it to sync some files with our devices.","title":"Seamless File Sync Solution With Syncthing"},{"content":"Data is arguably one of the most important assets in our modern world. We use computers, smartphones, and other devices to store and access our personal and professional information.\nHowever, these devices are not immune to failures or accidents. In the event of a hard drive crash, theft, or other catastrophic event, having a backup of your data is critical.\nIn this post, we will discuss the importance of backups, the 3-2-1 method, and how to backup your Linux, Windows, and Mac machines so that you can rest assured that your data is safe.\nWhy Backups Are Important We\u0026rsquo;ve all heard the horror stories of data being deleted or being lost by ransomware. When it comes to preparing for data loss in my environment, there are a couple key strategies one could use that could minimize the impact of being severely affected by data loss.\nData loss can have devastating consequences. If you lose your personal photos, documents, or other files, you may not be able to recover them. If you lose your work files, it could result in a loss of productivity and revenue for your business.\nBackups provide a way to protect your data against any potential for loss in the future.\nMethods / Strategies 3-2-1 Backup Method The 3-2-1 backup method is a simple but effective strategy for protecting your data. It involves creating three copies of your data, storing it in two different formats, and keeping one copy off-site. Here is how it works:\nThree copies of your data: This means that you have three copies of your data in case one or two copies become inaccessible or corrupted. Two different storage types: This means that you store your data in two different types of storage media, such as a hard drive and a cloud-based storage service. This protects against the risk of both storage types failing at the same time. One copy stored offsite: This means that you store one copy of your data in an offsite location, such as a cloud-based storage service or a physical location away from your primary storage site. This protects against the risk of data loss due to a physical disaster or theft. Incremental Backups This backup method only backs up changes made since the last backup. This means that it takes less time and storage space than a full backup.\nDifferential Backups This backup method backs up all changes made since the last full backup. This means that it takes more time and storage space than an incremental backup but less than a full backup.\nContinuous Data Protection Method This backup method automatically backs up changes in real-time, ensuring that the most up-to-date data is always backed up.\nCloud Backups This backup method stores your data on a remote server over the internet, providing an offsite backup solution that can be accessed from anywhere.\nLocal Backups This backup method involves backing up your data to a local storage device such as an external hard drive or USB drive.\nIt\u0026rsquo;s important to note that each backup method has its own strengths and weaknesses, so it\u0026rsquo;s essential to choose a backup method that suits your specific needs and circumstances.\nBasic Backup Guide For Your Machines How to Backup Your Windows Machine Windows is the most popular operating system used by consumers and businesses. Here are the steps to backup your Windows machine:\nConnect an external hard drive to your Windows machine. Click on the Start menu and type \u0026ldquo;backup and restore\u0026rdquo; in the search box. Click on \u0026ldquo;Backup and Restore (Windows 7)\u0026rdquo; and then click on \u0026ldquo;Set up backup.\u0026rdquo; Follow the prompts to select the files and folders you want to backup and choose your external hard drive as the backup destination. Click on \u0026ldquo;Save settings and run backup\u0026rdquo; to start the backup process. How to Backup Your Mac Machine Mac OS is a popular operating system used by many creative professionals. Here are the steps to backup your Mac machine:\nConnect an external hard drive to your Mac machine. Click on the Apple menu and select \u0026ldquo;System Preferences.\u0026rdquo; Click on \u0026ldquo;Time Machine.\u0026rdquo; Click on \u0026ldquo;Select Backup Disk\u0026rdquo; and choose your external hard drive as the backup destination. Click on \u0026ldquo;Back Up Now\u0026rdquo; to start the backup process. How to Backup Your Linux Machine Linux is a popular operating system used by many servers and developers.\nHere are some steps you can take to backup your Linux machine:\nConnect an external hard drive to your Linux machine. Open a terminal window and type the following command to create a backup of your entire system: 1 sudo tar cvpzf /backup.tar.gz --exclude=/backup.tar.gz --exclude=/proc --exclude=/tmp --exclude=/mnt --exclude=/dev --exclude=/sys / Wait for the backup process to complete. Copy the backup file to your external hard drive. You could also utilize a bash script if you wish, as mentioned in one of my previous articles.\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 #!/bin/bash backup_dirs=(\u0026#34;/etc\u0026#34; \u0026#34;/home\u0026#34; \u0026#34;/boot\u0026#34;) dest_dir=\u0026#34;/backup\u0026#34; backup_date=$(date +%b-%d-%y) echo \u0026#34;Starting backup of: ${backup_dirs[@]}\u0026#34; for i in \u0026#34;${backup_dirs[@]}\u0026#34;; do sudo tar -Pczf /tmp/$i-$backup_date.tar.gz $i if [ $? -eq 0 ]; then echo \u0026#34;$i backup succeeded.\u0026#34; else echo \u0026#34;$i backup failed.\u0026#34; fi done sudo mkdir -p $dest_dir sudo mv /tmp/*.gz $dest_dir echo \u0026#34;Backup is done.\u0026#34; Scheduling Make sure you have a backup schedule and keep your backup copies in a safe and secure location.\nTesting Your Backups In addition to backing up your data, it\u0026rsquo;s also important to test your backups regularly. This ensures that you can recover your data in case of a disaster. You can do this by restoring your backups to a different machine or location and checking if all the files are present and accessible. For a more realistic scenario, you could also simulate data loss and go through the process of recovering your data from there.\nMy Strategies for my Lab As of the writing of this post, I would say my current strategy is not a one size fits all approach, I try and mix some of these strategies together, but otherwise, you may do whatever works best for your environment.\nMonitoring I usually keep an eye for any SMART failures on my NAS\u0026rsquo;s RAID 1, I have alerts enabled through my NAS which alert me if SMART detects any potential failures with any of the drives.\nSynology Hyper Backup I keep incremental backups of some of the basic files from my SMB and NFS shares with Synology\u0026rsquo;s Hyper-Backup, and also utilize a cloud backup with Sync and pCloud as my providers.\nEncryption My uploaded backups are encrypted with Cryptomator and I only backup the most important data to the cloud, such as financial documents, identity documents, personal media like pictures or videos, notes, and other small sized data.\nLarge Media For all other large media, I try and take the 3-2-1 approach, but not fully. I have (1x) 12 TB external HDD, and (1x) 14 TB external HDD which keep an incremental and encrypted backup of all my other data.\nMulti Location Some drives are stored at my residence, I also have (1x) 2 TB drive with a copy of my encrypted cloud uploads that are updated every 3-6 months at another location that is not my residence.\nAlthough my approach is not perfect, I am constantly working my way towards adopting more of the best practices.\nConclusion In conclusion, backups are essential for protecting your data against loss. By following any of the above backup methods and regularly backing up your data, you can definitely make a difference, and ensure that your important files are safe and recoverable in case of a disaster.\nSo, don\u0026rsquo;t wait until it\u0026rsquo;s too late, start backing up your data today.\nLearn More 3-2-1 Strategy from Backblaze r/Datahoarder\u0026rsquo;s Backups Wiki List of Backup Software ","permalink":"https://netsparse.dev/posts/2023-03/data-backup-guide/","summary":"Data is arguably one of the most important assets in our modern world. We use computers, smartphones, and other devices to store and access our personal and professional information.\nHowever, these devices are not immune to failures or accidents. In the event of a hard drive crash, theft, or other catastrophic event, having a backup of your data is critical.\nIn this post, we will discuss the importance of backups, the 3-2-1 method, and how to backup your Linux, Windows, and Mac machines so that you can rest assured that your data is safe.","title":"Quick Data Backup Guide"},{"content":"PowerShell is a command-line scripting language developed by Microsoft that is designed to automate administrative tasks and manage system configurations. It provides a powerful framework for managing Windows-based systems and automating repetitive tasks.\nScripts are written in the PowerShell scripting language, which is based on the .NET framework.\nThe language includes features such as variables, loops, conditionals, and functions, which allow you to write scripts to perform a wide range of tasks.\nIn this guide, I\u0026rsquo;ll guide you through the process of getting started with PowerShell, and provide some practical examples of how you can use it to perform some common tasks.\nGetting Started Click on the Start menu and type \u0026ldquo;PowerShell\u0026rdquo; in the search bar.\nor\nPress Win+X, you may see underlines under the options. Press I, PowerShell will open.\nWin+X A for an elevated prompt\nOnce you have opened the PowerShell console, you can start entering commands.\nPowerShell commands are called cmdlets, and they are structured in a verb-noun format.\nCheck PS Version To verify which version of PowerShell you are running, run:\n1 $PSVersionTable List Running Processes For example, to display a list of all the processes running on your machine, you would enter the following command:\n1 Get-Process This will display a list of all the running processes, including their names, process IDs, and memory usage.\nExecution Policy The execution policy is designed to prevent a user from unknowingly running a script. Although not a security boundary, it prevents accidental launching of scripts.\n1 Get-ExecutionPolicy PowerShell scripts can\u0026rsquo;t be run at all when the execution policy is set to Restricted. This is the default setting on all Windows client operating systems.\nIf you need to set the execution policy, run Set-ExecutionPolicy with the recommended RemoteSigned policy.\n1 Set-ExecutionPolicy -ExecutionPolicy RemoteSigned Quick Practical Examples Checking Disk Space 1 Get-PSDrive | Where-Object {$_.Provider -like \u0026#34;*FileSystem\u0026#34;} | Format-Table Name, Used, Free, @{Name=\u0026#34;Capacity\u0026#34;;Expression={(\u0026#34;{0:N2}\u0026#34; -f (($_.Used + $_.Free) / 1GB)) + \u0026#34; GB\u0026#34;}} Restarting a Service For example, to restart the Windows Update service, you would enter the following command:\n1 Restart-Service -Name wuauserv Creating a User Account The following command creates a new user account named John with the password P@ssw0rd:\n1 New-LocalUser -Name \u0026#34;John\u0026#34; -Password (ConvertTo-SecureString \u0026#34;P@ssw0rd\u0026#34; -AsPlainText -Force) Removing Old Files The following command removes all files in the C:\\Temp directory that are older than 30 days:\n1 Get-ChildItem \u0026#34;C:\\Temp\u0026#34; -Recurse | Where-Object {$_.LastWriteTime -lt (Get-Date).AddDays(-30)} | Remove-Item -Force Moving Files by File Extension This is a PowerShell script that moves files of a given file extension from a source directory to a destination directory on the OS all while promting for user input.\n1 2 3 4 5 6 7 8 9 $sourcePath = Read-Host \u0026#34;Enter the source directory path containing the files to be moved\u0026#34; $destinationPath = Read-Host \u0026#34;Enter the destination directory path where the files will be moved\u0026#34; $extension = Read-Host \u0026#34;Enter the file extension to filter files (e.g. *.txt)\u0026#34; Get-ChildItem $sourcePath -Filter $extension | ForEach-Object { $newPath = Join-Path $destinationPath $_.Name Move-Item $_.FullName $newPath -Force } More Scripts You can check out more scripts that have been developed by the community on GitHub, and also some provided by Microsoft here.\nConclusion PowerShell is a valuable tool for system administrators, enabling them to automate tasks and streamline their Windows environment.\nWith its powerful capabilities and user-friendly interface, it is an essential tool for any Windows-based IT environment.\nLearn More Windows PowerShell Survival Guide MS introduction to PowerShell Guru99 Official PowerShell Documentation PowerShell Overview Some good examples ","permalink":"https://netsparse.dev/posts/2023-03/quick-powershell-scripting/","summary":"PowerShell is a command-line scripting language developed by Microsoft that is designed to automate administrative tasks and manage system configurations. It provides a powerful framework for managing Windows-based systems and automating repetitive tasks.\nScripts are written in the PowerShell scripting language, which is based on the .NET framework.\nThe language includes features such as variables, loops, conditionals, and functions, which allow you to write scripts to perform a wide range of tasks.","title":"Quick Intro To Powershell"},{"content":"Bash scripting is a powerful tool that enables users to automate tasks and streamline workflows in Unix-based operating systems, such as Linux and macOS.\nIt can be used for a variety of purposes, including system administration, web development, data analysis, and more.\nHere\u0026rsquo;s a quick overview from Fireship.io.\nComponents Commands Consist of a series of commands that are executed one after the other.\nThese commands can be standard Linux commands or custom commands written specifically for the script.\n1 2 3 echo \u0026#34;Hello World\u0026#34; # prints \u0026#34;Hello World\u0026#34; to the console ls /home/user # lists files in the user\u0026#39;s home directory touch new_file.txt # creates a new empty file named \u0026#34;new_file.txt\u0026#34; Variables Use variables to store and manipulate data.\nVariables can be assigned values, used in arithmetic and string operations, and passed as arguments to commands.\n1 2 3 4 5 name=\u0026#34;John\u0026#34; echo \u0026#34;Hello $name\u0026#34; # prints \u0026#34;Hello John\u0026#34; to the console number=10 result=$((number + 5)) echo $result # prints \u0026#34;15\u0026#34; to the console Control Structures You can use control structures like if-else statements, loops, and functions to control the flow of execution.\nThese structures allow scripts to make decisions, repeat tasks, and perform complex operations.\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 if [[ -d \u0026#34;/home/user\u0026#34; ]]; then echo \u0026#34;The /home/user directory exists\u0026#34; else echo \u0026#34;The /home/user directory does not exist\u0026#34; fi for i in {1..5}; do echo $i done function say_hello() { echo \u0026#34;Hello\u0026#34; } say_hello Input and Output Bash scripts can read input from various sources, including standard input, command-line arguments, and files.\nThey can also write output to standard output, files, and other destinations.\n1 2 3 4 5 read -p \u0026#34;What is your name? \u0026#34; name echo \u0026#34;Hello $name\u0026#34; cat file.txt # prints the contents of file.txt to the console echo \u0026#34;Hello\u0026#34; \u0026gt; file.txt # writes \u0026#34;Hello\u0026#34; to file.txt Error Handling Errors and exceptions using error codes, traps, and logging.\nThey can also send email notifications and perform other actions in response to errors.\n1 2 3 4 5 6 7 command_that_might_fail || echo \u0026#34;An error occurred\u0026#34; trap \u0026#39;echo \u0026#34;An error occurred\u0026#34;; exit 1\u0026#39; ERR echo \u0026#34;Starting script\u0026#34; some_command || exit 1 echo \u0026#34;Script completed successfully\u0026#34; Regular Expressions (RegEx) You can use regular expressions to perform pattern matching and text manipulation.\nRegular expressions are a powerful tool for searching and replacing text within a script.\nYou can check out RegExr to learn more about how they work.\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 # Extracting email addresses from a file cat file.txt | grep -oE \u0026#39;[A-Za-z0-9._%+-]+@[A-Za-z0-9.-]+\\.[A-Z|a-z]{2,}\u0026#39; # Extracting phone numbers from a string text=\u0026#34;My phone number is 123-456-7890\u0026#34; echo $text | grep -oE \u0026#39;[0-9]{3}-[0-9]{3}-[0-9]{4}\u0026#39; # Replacing all occurrences of a string in multiple files find . -type f -name \u0026#39;*.txt\u0026#39; -exec sed -i \u0026#39;s/old_string/new_string/g\u0026#39; {} + # Extracting all URLs from an HTML file cat index.html | grep -oE \u0026#39;https?://[^ ]+\u0026#39; # Replacing all occurrences of \u0026#39;foo\u0026#39; with \u0026#39;bar\u0026#39; in a string text=\u0026#34;The quick brown foo jumps over the lazy dog\u0026#34; echo ${text/foo/bar} Functions Define functions to encapsulate and reuse code.\nFunctions can take arguments, return values, and be used to perform complex tasks.\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 # A function that returns the sum of two numbers function add_numbers() { local result=$(( $1 + $2 )) echo $result } # A function that prints a message function say_hello() { echo \u0026#34;Hello, world!\u0026#34; } # Using the functions sum=$(add_numbers 5 7) echo \u0026#34;The sum is: $sum\u0026#34; say_hello Get Started For Basic Systems Administration In this post, we\u0026rsquo;ll explore some of use cases for bash scripting and provide some examples that could be of use for you and your environment.\nPerforming Updates We know updates are definitely important, so why not automate them in some way.\nCreate a auto-updates.sh script and add the following:\n1 2 3 #!/bin/bash sudo apt-get update sudo apt-get upgrade -y Make Executable 1 chmod +x /path/to/auto-updates.sh You can also add this script to the crontab to automate your updates for your system.\nRenaming Files Renaming files can be a tedious and time-consuming task, especially when you have a large number of files to rename.\nWe could make it easier for ourselves by creating a script to automate this for us.\nThe basic command to rename files in Bash is mv.\nTo rename a file named old_name.txt to new_name.txt, you can use the mv command as below:\n1 mv old_name.txt new_name.txt Renaming Multiple Files If you want to rename multiple files at once, you can use a Bash script to automate the process.\nHere is an example of how to rename all files in a directory with the .txt extension:\n1 2 3 4 5 #!/bin/bash for file in *.txt do mv \u0026#34;$file\u0026#34; \u0026#34;new_${file}\u0026#34; done This script will add the prefix new_ to the beginning of each file name with the .txt extension.\nMoving Files Moving files is another task that can be automated with Bash scripting.\nThe mv command can also be used to move files from one directory to another.\nHere is an example of how to move a file named file.txt from the current directory to the directory /home/user/documents/:\n1 mv file.txt /home/user/documents/ This command will move the file file.txt to the directory /home/user/documents/.\nMoving Multiple Files To move multiple files at once, you can use a Bash script.\nHere is an example of how to move all files in a directory with the .txt extension to a new directory:\n1 2 3 4 5 6 #!/bin/bash mkdir /home/user/documents/txt_files for file in *.txt do mv \u0026#34;$file\u0026#34; /home/user/documents/txt_files/ done Performing Backups 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 #!/bin/bash backup_dirs=(\u0026#34;/etc\u0026#34; \u0026#34;/home\u0026#34; \u0026#34;/boot\u0026#34;) dest_dir=\u0026#34;/backup\u0026#34; backup_date=$(date +%b-%d-%y) echo \u0026#34;Starting backup of: ${backup_dirs[@]}\u0026#34; for i in \u0026#34;${backup_dirs[@]}\u0026#34;; do sudo tar -Pczf /tmp/$i-$backup_date.tar.gz $i if [ $? -eq 0 ]; then echo \u0026#34;$i backup succeeded.\u0026#34; else echo \u0026#34;$i backup failed.\u0026#34; fi done sudo mkdir -p $dest_dir sudo mv /tmp/*.gz $dest_dir echo \u0026#34;Backup is done.\u0026#34; This should perform a backup with tar of the /etc, /home, and boot directories to the specified directory (in this case/backup). Which could then be transferred to another machine once the backup is finished.\nOther Use Cases Web Development Bash scripts are also useful for web developers who need to automate repetitive tasks such as deploying code, running tests, and building websites.\nFor example, a web developer can use a bash script to automate the process of deploying code to a production server.\n1 2 3 4 5 #!/bin/bash git pull npm install npm run build rsync -avz --exclude=node_modules /path/to/local/code/ user@server:/path/to/production/code/ Data Analysis Bash scripting is also useful for parsing fairly large amounts of data, and automating tasks such as data cleaning, data transformation, and data visualization.\nFor example, you can use a bash script to clean a large CSV file and generate a summary report.\nThe script can contain commands that remove duplicates, filter rows, and aggregate data.\nYou\u0026rsquo;ll need the csvkit package which can be installed with apt install.\n1 2 #!/bin/bash csvclean input.csv | csvstat \u0026gt; report.txt Docker Quickly Install Docker 1 2 3 4 5 6 7 8 9 10 11 #!/bin/bash # Install Docker sudo apt-get update sudo apt-get install -y docker.io # Start Docker daemon sudo systemctl start docker # Download and run \u0026#34;hello-world\u0026#34; container sudo docker run hello-world Cron cron is a utility program that allows users to schedule commands or scripts to run automatically at specified intervals in Linux-based operating systems.\nThe name \u0026ldquo;cron\u0026rdquo; comes from the Greek word \u0026ldquo;chronos\u0026rdquo;, which means \u0026ldquo;time\u0026rdquo;. The cron daemon is a background process that runs continuously and checks the crontab files for any scheduled jobs to run.\nAdding Items to the Cron 1 crontab -e If this is the first time you\u0026rsquo;re editing your crontab file, the system may ask you to choose an editor.\nIn the editor, add a new line for each command or script you want to schedule. The format of the line is as follows:\n1 * * * * * command-to-be-executed The asterisks represent the timing specification for the command, which defines when it should be executed.\nFor example, if you want a command to run every day at midnight, you would use the following line:\n1 0 0 * * * command-to-be-executed The cron daemon will automatically read the updated crontab file and start executing the scheduled commands at the specified intervals.\nYou can verify that your new items have been added to your crontab file by typing the following command:\n1 crontab -l Check out this helpful tool for editing your cron schedule expressions.\nAdd Scripts to Cron 1 * * * * * /path/to/script.sh If you want to redirect stdout and errors to a file, you can modify the cron command like this:\n1 0 0 * * * /path/to/script.sh \u0026gt;\u0026gt; /path/to/output.log 2\u0026gt;\u0026amp;1 Automating Backups You can utilize scripts and cron to perform backups, send them off to a remote server, and send a notification when they are done.\nExample:\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 #!/bin/bash # Backup directory path local_backup_dir=\u0026#34;$HOME/backups\u0026#34; # Remote server IP address remote_user=\u0026#34;example\u0026#34; remote_server=\u0026#34;192.168.2.200\u0026#34; remote_backup_dir=\u0026#34;/backups\u0026#34; # Email address for notifications notification_email=\u0026#34;alerts@example.com\u0026#34; # Create a backup with tar in local dir, send it to a remote server, and send a notification when done mkdir -p \u0026#34;$local_backup_dir\u0026#34; backup_path=\u0026#34;$local_backup_dir/$(date +%Y-%m-%d)\u0026#34; tar -czvf \u0026#34;$backup_path.tar.gz\u0026#34; -C \u0026#34;$HOME\u0026#34; \u0026#34;$(basename $local_backup_dir)\u0026#34; if [ $? -eq 0 ]; then echo \u0026#34;Backup succeeded.\u0026#34; else echo \u0026#34;Backup failed.\u0026#34; exit 1 fi rsync -avz --delete \u0026#34;$backup_path.tar.gz\u0026#34; \u0026#34;$remote_user@$remote_server:$remote_backup_dir\u0026#34; if [ $? -eq 0 ]; then echo \u0026#34;Transfer succeeded.\u0026#34; else echo \u0026#34;Transfer failed.\u0026#34; exit 1 fi echo \u0026#34;Backup completed on $(date).\u0026#34; | mail -s \u0026#34;Backup completed\u0026#34; \u0026#34;$notification_email\u0026#34; # Define a cronjob that runs this backup every 3 days at 10pm (crontab -l ; echo \u0026#34;0 22 */3 * * /bin/bash /path/to/script.sh\u0026#34;) | crontab - Snapshots with Timeshift Timeshift is a free and open-source backup/restore utility for Linux systems.\nIt creates snapshots of the file system, allowing users to restore their system to a previous state if needed. Timeshift can be run manually or scheduled to run automatically using cron.\nSnapshots can be stored locally or remotely, and users can choose the number of snapshots to keep and the frequency of snapshots.\nYou can create a bash script for defining how you would like timeshift to run, make sure to include sudo when running:\n1 2 3 4 5 6 7 8 9 10 11 12 13 #!/bin/bash # Set the snapshot directory snapshot_dir=\u0026#34;/run/timeshift/\u0026lt;drive\u0026gt;/backup\u0026#34; # Set the maximum number of snapshots to keep max_snapshots=10 # Set the backup level (can be \u0026#34;system\u0026#34; or \u0026#34;home\u0026#34;) backup_level=\u0026#34;system\u0026#34; # Create a new snapshot with Timeshift timeshift --snapshot --create --comments \u0026#34;Automated snapshot on $(date +%Y-%m-%d)\u0026#34; --backup-device \u0026#34;$backup_level\u0026#34; You can then add this entry to your crontab to have cron run it every 3 days at 1am, or after your backups are done.\n1 0 1 */3 * * /home/user/scripts/timeshift-auto.sh If you would like to simply add it to cron manually, you can simply add the following:\nMake sure to specify the \u0026lt;drive\u0026gt; under --backup-device.\n1 0 1 */3 * * /usr/bin/timeshift --snapshot --create --comments \u0026#34;Automated snapshot on $(date +\\%Y-\\%m-\\%d)\u0026#34; --backup-device \u0026#34;/run/timeshift/\u0026lt;drive\u0026gt;/backup\u0026#34; --scripted Learn More Make sure to check out the official Bash manual and other awesome guides like The Linux Documentation Project\u0026rsquo;s Beginner and Advanced Bash Scripting Guide, GreyCat\u0026rsquo;s BashGuide, and commandlinefu.\nConclusion Although Bash is useful for automating tasks on a single host, if you wish to replicate this and multiply it across a multitude of hosts, you should take a look at my other Ansible post, where we take this to another level.\nIn conclusion, bash scripting is a powerful tool that enables users to automate tasks and streamline workflows in Unix-based operating systems.\nBy writing scripts, you can save time, reduce errors, and improve productivity.\nLearn More Official GNU Bash Manual learnshell.org BashGuide TLDP MrTutorize YouTube Series Code Academy Devhints.io Cheat Sheet BashHackers Tools Shellcheck ","permalink":"https://netsparse.dev/posts/2023-03/quick-bash-scripting/","summary":"Bash scripting is a powerful tool that enables users to automate tasks and streamline workflows in Unix-based operating systems, such as Linux and macOS.\nIt can be used for a variety of purposes, including system administration, web development, data analysis, and more.\nHere\u0026rsquo;s a quick overview from Fireship.io.\nComponents Commands Consist of a series of commands that are executed one after the other.\nThese commands can be standard Linux commands or custom commands written specifically for the script.","title":"Quick Intro To Bash Scripting"},{"content":"Git is a powerful and widely used version control system that allows developers to manage changes to their codebase efficiently.\nWhether you are working on a solo project or collaborating with a team, Git provides a simple and effective way to keep track of changes and revert to previous versions if necessary.\nIn this article, we will cover the basics of using Git, including creating a repository, making changes, committing those changes, and pushing them to a remote repository.\nHere\u0026rsquo;s a quick overview from Fireship.io.\n\u0026ldquo;Git\u0026rdquo; Started Download the appropriate package for your system.\nWindows Official Downloads or choco install git Mac OS Official Downloads or brew install git Linux Official Downloads or apt install git for Debian/Ubuntu. Once you have installed Git, you can open a command prompt or terminal window and enter the following command to check that Git is installed and working correctly:\n1 git --version Creating a Repository Once Git is installed, you can start using it to manage your code.\nThe first step is to create a new repository. A repository is a collection of files and directories that make up your project.\nTo create a new repository, navigate to the directory where you want to store your project and enter the following command:\n1 git init This command initializes a new Git repository in the current directory. Git will create a hidden .git directory that contains all the information necessary to track changes to your code.\nManagement Making Changes With a repository created, you can start making changes to your code.\nTo track changes in Git, you need to first stage the changes using the git add command.\nFor example, to stage all changes in the current directory, enter the following command:\n1 git add . This command stages all changes in the current directory, including new files and modifications to existing files.\nYou can also stage individual files or directories by specifying their names instead of the ..\nCommitting Changes Once you have staged your changes, you can commit them to the repository using the git commit command.\nA commit is a snapshot of your code at a specific point in time, and it includes a message describing the changes you made.\nTo commit your changes, enter the following command:\n1 git commit -m \u0026#34;Commit message\u0026#34; Replace Commit message with a brief description of the changes you made.\nIt\u0026rsquo;s a good idea to keep commit messages short and descriptive, so that other developers can easily understand what changes were made.\nPushing to a Remote Repository By default, Git stores all changes in the local repository on your machine.\nHowever, you can also push changes to a remote repository, such as GitHub, GitLab, or Bitbucket.\nTo push your changes to a remote repository, you need to first add the remote repository as a remote.\nFor example, to add a remote named origin for a repository on GitHub, enter the following command:\n1 git remote add origin https://github.com/username/repo.git Replace username with your GitHub username and repo with the name of your repository.\nYou can also use SSH instead of HTTPS if you prefer.\nOnce you have added a remote repository, you can push your changes using the git push command.\nFor example, to push changes to the main branch of the origin remote, enter the following command:\n1 git push origin main Replace main with the name of the branch you want to push to.\nIf you have never pushed to the remote repository before, Git may prompt you to enter your GitHub username and password.\nRevert Changes To revert changes in Git, use the git revert command followed by the commit hash of the commit you want to undo.\nGit will create a new commit that undoes the changes made by the original commit.\nUse the git log command to find the commit hash of the commit you want to revert. This will display a list of all the commits in the repository, along with their commit hash, author, date, and commit message.\n1 git log Once you\u0026rsquo;ve found the commit you want to revert, use the git revert command followed by the commit hash to create a new commit that undoes the changes made by the original commit.\n1 git revert \u0026lt;commit hash\u0026gt; 1 git revert 12a34b56c Git will open a text editor for you to enter a commit message for the new revert commit.\nSave and close the commit message file. Git will then create a new commit that undoes the changes made by the original commit.\nUse the git log command again to confirm that the new revert commit was created and the changes were undone.\nAnd that\u0026rsquo;s it!\nConclusion In this article, we covered the basics of using Git to manage your code.\nGit is a powerful tool for managing and versioning code and allows you to keep track of changes made to your codebase, collaborate with other developers, and easily revert changes when necessary.\nOverall, Git is an essential tool for any IT professional looking to manage and version their code effectively.\nLearn More Official Git Book Official Documentation Visual Cheat Sheet Git Videos GitHub Cheat Sheets GitHub Training Manual ","permalink":"https://netsparse.dev/posts/2023-03/getting-started-with-git/","summary":"Git is a powerful and widely used version control system that allows developers to manage changes to their codebase efficiently.\nWhether you are working on a solo project or collaborating with a team, Git provides a simple and effective way to keep track of changes and revert to previous versions if necessary.\nIn this article, we will cover the basics of using Git, including creating a repository, making changes, committing those changes, and pushing them to a remote repository.","title":"Getting Started With Git"},{"content":"Python is a high-level, interpreted programming language that is widely used for web development, data analysis, artificial intelligence, and other applications.\nIt has a clean syntax and is easy to learn, making it a great choice for beginners as well as experienced developers.\nHere\u0026rsquo;s a quick overview from Fireship.io.\nOverview Variables and Data Types In Python, variables are used to store values such as numbers, strings, and other data types.\nTo assign a value to a variable, you simply use the \u0026ldquo;=\u0026rdquo; sign.\nFor example, to assign the value 5 to a variable called \u0026ldquo;x\u0026rdquo;, you would write:\n1 x = 5 Python has several built-in data types:\nintegers (whole numbers) floats (decimal numbers) booleans (represent True or False) strings (used to represent text) lists (used to store collections of values) 1 2 3 4 5 6 # Examples of data types in Python a = 5 # integer b = 3.14 # float c = True # boolean d = \u0026#34;Hello\u0026#34; # string e = [1, 2, 3] # list Control Flow Control flow refers to the way that a program executes its instructions based on certain conditions.\nPython uses if-else statements and loops to control the flow of a program.\nAn if-else statement is used to execute certain code if a certain condition is met, and other code if it is not.\nFor example:\n1 2 3 4 5 x = 5 if x \u0026gt; 10: print(\u0026#34;x is greater than 10\u0026#34;) else: print(\u0026#34;x is less than or equal to 10\u0026#34;) A loop is used to repeat a certain block of code a certain number of times, or until a certain condition is met.\nFor example:\n1 2 3 4 5 6 7 8 9 # While loop i = 0 while i \u0026lt; 5: print(i) i += 1 # For loop for i in range(5): print(i) Functions Functions are used to group together a certain block of code that can be called and executed multiple times throughout a program.\nA function can take in certain parameters and can return a certain value.\nExample:\n1 2 3 4 5 6 # Function that adds two numbers def add_numbers(x, y): return x + y result = add_numbers(3, 4) print(result) Output:\n1 7 Modules Modules are used to group together certain functions and variables that can be imported and used in other Python programs.\nPython has a large number of built-in modules that provide useful functionality, such as the math module for performing mathematical calculations.\nYou can also create your own modules to organize your code and make it more reusable.\nExample:\n1 2 3 4 import math x = math.sqrt(25) print(x) Output:\n1 5 Web Frameworks Frameworks provide a set of libraries and tools to help developers build web applications more quickly and easily, typically by provideing a set of features, such as routing, templating, database integration, and security, that are common to most web applications\nFlask Flask is one of the popular web frameworks for building web applications in Python, it is lightweight, flexible and provides tools and libraries for handling HTTP requests, rendering templates, managing sessions, and interacting with databases.\nDjango Django, on the other hand, is a full-stack framework, meaning it provides many similar built-in tools and features as Flask, but includes more, it is usually better suited for building large, complex web applications with a lot of functionality.\nOther Notable Frameworks Pyramid CherryPy And a lot more\u0026hellip; Package Management The Python Package Index (PyPI) is a repository of software for the Python programming language.\nPyPI helps you find and install software developed and shared by the Python community. You can learn more about installing packages on the PyPi packaging documentation.\nBuild a Simple Calculator Now that we have covered some of the basics of Python, let\u0026rsquo;s create a simple calculator program.\nWe\u0026rsquo;ll create a program that will take in two numbers and perform simple operations on them, such as addition, subtraction, multiplication, or division.\nCreate Your Python File Create a .py file, in this case, we can call it simple_calculator.py. Copy and paste the following code: 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 # define a function for each operation def add(x, y): return x + y def subtract(x, y): return x - y def multiply(x, y): return x * y def divide(x, y): if y != 0: return x / y else: return \u0026#34;Error: Division by zero\u0026#34; # get input from the user x = float(input(\u0026#34;Enter the first number: \u0026#34;)) y = float(input(\u0026#34;Enter the second number: \u0026#34;)) # display menu of available operations print(\u0026#34;Select operation:\u0026#34;) print(\u0026#34;1. Add\u0026#34;) print(\u0026#34;2. Subtract\u0026#34;) print(\u0026#34;3. Multiply\u0026#34;) print(\u0026#34;4. Divide\u0026#34;) # get user\u0026#39;s choice of operation choice = input(\u0026#34;Enter choice (1/2/3/4): \u0026#34;) # perform the selected operation if choice == \u0026#39;1\u0026#39;: print(x, \u0026#34;+\u0026#34;, y, \u0026#34;=\u0026#34;, add(x, y)) elif choice == \u0026#39;2\u0026#39;: print(x, \u0026#34;-\u0026#34;, y, \u0026#34;=\u0026#34;, subtract(x, y)) elif choice == \u0026#39;3\u0026#39;: print(x, \u0026#34;*\u0026#34;, y, \u0026#34;=\u0026#34;, multiply(x, y)) elif choice == \u0026#39;4\u0026#39;: print(x, \u0026#34;/\u0026#34;, y, \u0026#34;=\u0026#34;, divide(x, y)) else: print(\u0026#34;Invalid input\u0026#34;) This should give us a simple calculator we can play around with, it utilizes Python\u0026rsquo;s built-in calculator module, which means we don\u0026rsquo;t have to define all the operators and such.\nRun 1 python simple_calculator.py You\u0026rsquo;ll be prompted to enter a first number and a second number, then from there you can select which operation to perform on these two numbers.\nIt would look something like this:\n1 2 3 4 5 6 7 8 9 Enter the first number: 254 Enter the second number: 127 Select operation: 1. Add 2. Subtract 3. Multiply 4. Divide Enter choice (1/2/3/4): 3 254.0 * 127.0 = 32258.0 Awesome! Now you\u0026rsquo;ve built yourself a handy calculator in Python that works in your CLI!\nBuild a Calculator App for the Web Using Flask What we\u0026rsquo;ll do next is re-create the calculator app in the web browser and we\u0026rsquo;ll utilize Flask to run this calculator as a web app, giving us more of a graphical way to interact with it.\nInstall Flask 1 pip install Flask Create Your Python File Create your python file, in this case, we can call it web_calculator.py, but you can name it anything you want.\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 from flask import Flask, request, render_template app = Flask(__name__) @app.route(\u0026#34;/\u0026#34;) def home(): return render_template(\u0026#34;index.html\u0026#34;) @app.route(\u0026#34;/calculate\u0026#34;, methods=[\u0026#34;POST\u0026#34;]) def calculate(): operation = request.form[\u0026#34;operation\u0026#34;] x = float(request.form[\u0026#34;x\u0026#34;]) y = float(request.form[\u0026#34;y\u0026#34;]) result = None if operation == \u0026#34;add\u0026#34;: result = x + y elif operation == \u0026#34;subtract\u0026#34;: result = x - y elif operation == \u0026#34;multiply\u0026#34;: result = x * y elif operation == \u0026#34;divide\u0026#34;: if y != 0: result = x / y else: result = \u0026#34;Error: Division by zero\u0026#34; return render_template(\u0026#34;index.html\u0026#34;, result=result) if __name__ == \u0026#34;__main__\u0026#34;: app.run(debug=True) Here, we have defined two routes. The first route, \u0026ldquo;/\u0026rdquo;, displays a simple HTML form that allows the user to input two numbers and select an operation.\nThe second route, \u0026ldquo;/calculate\u0026rdquo;, is called when the form is submitted and performs the selected operation on the two numbers.\nBuild the HTML file Create an index.html to include our new code for the calculator app. Create a folder titled templates, and move your index.html file into it. 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 \u0026lt;!DOCTYPE html\u0026gt; \u0026lt;html\u0026gt; \u0026lt;head\u0026gt; \u0026lt;title\u0026gt;Calculator\u0026lt;/title\u0026gt; \u0026lt;/head\u0026gt; \u0026lt;body\u0026gt; \u0026lt;h1\u0026gt;Calculator\u0026lt;/h1\u0026gt; \u0026lt;form method=\u0026#34;post\u0026#34; action=\u0026#34;/calculate\u0026#34;\u0026gt; \u0026lt;label for=\u0026#34;x\u0026#34;\u0026gt;Num #1:\u0026lt;/label\u0026gt; \u0026lt;input type=\u0026#34;number\u0026#34; name=\u0026#34;x\u0026#34; required\u0026gt; \u0026lt;label for=\u0026#34;y\u0026#34;\u0026gt;Num #2:\u0026lt;/label\u0026gt; \u0026lt;input type=\u0026#34;number\u0026#34; name=\u0026#34;y\u0026#34; required\u0026gt; \u0026lt;br\u0026gt; \u0026lt;label for=\u0026#34;operation\u0026#34;\u0026gt;Operation:\u0026lt;/label\u0026gt; \u0026lt;select name=\u0026#34;operation\u0026#34;\u0026gt; \u0026lt;option value=\u0026#34;add\u0026#34;\u0026gt;Add\u0026lt;/option\u0026gt; \u0026lt;option value=\u0026#34;subtract\u0026#34;\u0026gt;Subtract\u0026lt;/option\u0026gt; \u0026lt;option value=\u0026#34;multiply\u0026#34;\u0026gt;Multiply\u0026lt;/option\u0026gt; \u0026lt;option value=\u0026#34;divide\u0026#34;\u0026gt;Divide\u0026lt;/option\u0026gt; \u0026lt;/select\u0026gt; \u0026lt;br\u0026gt;\u0026lt;br\u0026gt; \u0026lt;input type=\u0026#34;submit\u0026#34; value=\u0026#34;Calculate\u0026#34;\u0026gt; \u0026lt;/form\u0026gt; {% if result %} \u0026lt;h2\u0026gt;Result: {{ result }}\u0026lt;/h2\u0026gt; {% endif %} \u0026lt;/body\u0026gt; \u0026lt;/html\u0026gt; Run 1 python web_calculator.py This will start a local web server that you can access in your web browser at:\n1 http://localhost:5000 Now you\u0026rsquo;ve set up a simple calculator with Python and Flask that runs on the browser!\nAdd In Some CSS (Optional) If you wish to make the design of the calculator look a bit nicer, you could write up a css file for it.\nIn the same directory as your .py, create a folder titled static. Inside this folder create your css file, you can call it style.css. You can use the template below to give the web app a material design look:\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 /* Set the font family and size */ body { font-family: Roboto, sans-serif; font-size: 16px; } /* Add padding to the body */ body { padding: 24px; } /* Center the calculator heading */ h1 { text-align: center; } /* Add some margin between form elements */ form { margin-top: 16px; margin-bottom: 16px; } /* Style the input fields */ input[type=\u0026#34;number\u0026#34;] { border: none; border-bottom: 1px solid #ccc; outline: none; padding: 8px; font-size: 16px; } /* Style the select element */ select { border: none; border-bottom: 1px solid #ccc; outline: none; padding: 8px; font-size: 16px; } /* Style the submit button */ input[type=\u0026#34;submit\u0026#34;] { background-color: #2196F3; color: white; border: none; padding: 8px 16px; font-size: 16px; border-radius: 4px; cursor: pointer; transition: background-color 0.3s; } input[type=\u0026#34;submit\u0026#34;]:hover { background-color: #1976D2; } /* Style the result heading */ h2 { text-align: center; } Now make sure to go back to your index.html file and link the newly created style.css by adding it inside of the \u0026lt;head\u0026gt;.\n1 \u0026lt;link rel=\u0026#34;stylesheet\u0026#34; type=\u0026#34;text/css\u0026#34; href=\u0026#34;{{ url_for(\u0026#39;static\u0026#39;, filename=\u0026#39;style.css\u0026#39;) }}\u0026#34;\u0026gt; You should now see your calculator with a more polished look:\nThat\u0026rsquo;s it! You now have a simple calculator web app that you can use to perform calculations in your web browser.\nYou can always use your built-in calculator on your system, but we all know it\u0026rsquo;s not as cool as one that we can build!\nQuick Tip If you wish to version control your code after building such an awesome app, check out how to use Git and push it to a central source like GitHub.\nFore example, you can always check out the code for this project.\nConclusion Overall, Python is awesome and helpful because it is versatile, easy-to-learn, and has a thriving community that supports its development and growth.\nIts many benefits make it an excellent choice for anyone who wants to learn a powerful and widely-used programming language and build potentially cool stuff with it.\nLearn More Official Documentation Python Library Reference Python Tutorial Additional Python 4 Everybody (PY4E) Al Sweigart\u0026rsquo;s Automate The Boring Stuff with Python Fireship.io Python Open Source CS Degree GitHub Resource OSSU CS David Beazley\u0026rsquo;s Python Course Full Stack Python YouTube (Corey Schafer) ","permalink":"https://netsparse.dev/posts/2023-03/hands-on-python/","summary":"Python is a high-level, interpreted programming language that is widely used for web development, data analysis, artificial intelligence, and other applications.\nIt has a clean syntax and is easy to learn, making it a great choice for beginners as well as experienced developers.\nHere\u0026rsquo;s a quick overview from Fireship.io.\nOverview Variables and Data Types In Python, variables are used to store values such as numbers, strings, and other data types.","title":"Hands-on with Python"},{"content":"WireGuard is a fast and secure VPN protocol that uses state-of-the-art cryptography. It is designed to be easy to implement and manage, and has a minimal attack surface. Its simplicity and efficiency make it well-suited for use in mobile devices and large-scale deployments.\nNote: Before making any major changes on your EdgeOS router, always make a backup. Refer to the official documentation on how to perform one.\nBreakdown Step 1. Installation Note: The following installation guide was verified working on EdgeOS v2.0.9-hotfix.4 as of Feb 2023.\nVerify your EdgeOS version 1 show version Download Wireguard Head over to WireGuard\u0026rsquo;s EdgeOS releases and look for the release that matches your platform/version.\nOn the ER-X, use curl to download the .deb file\n1 curl -OL https://github.com/WireGuard/wireguard-vyatta-ubnt/releases/download/1.0.20220627-1/e50-v2-v1.0.20220627-v1.0.20210914.deb Install with dpkg 1 sudo dpkg -i e50-v2-v1.0.20220627-v1.0.20210914.deb Output Log\n1 2 3 4 5 6 7 8 9 user@ER-X:~$ sudo dpkg -i e50-v2-v1.0.20220627-v1.0.20210914.deb Selecting previously unselected package wireguard. (Reading database ... 37091 files and directories currently installed.) Preparing to unpack e50-v2-v1.0.20220627-v1.0.20210914.deb ... Adding \u0026#39;diversion of /opt/vyatta/share/perl5/Vyatta/Interface.pm to /opt/vyatta/share/perl5/Vyatta/Interface.pm.vyatta by wireguard\u0026#39; Adding \u0026#39;diversion of /opt/vyatta/share/vyatta-cfg/templates/firewall/options/mss-clamp/interface-type/node.def to /opt/vyatta/share/vyatta-cfg/templates/firewall/options/mss-clamp/interface-type/node.def.vyatta by wireguard\u0026#39; Adding \u0026#39;diversion of /opt/vyatta/share/vyatta-cfg/templates/firewall/options/mss-clamp6/interface-type/node.def to /opt/vyatta/share/vyatta-cfg/templates/firewall/options/mss-clamp6/interface-type/node.def.vyatta by wireguard\u0026#39; Unpacking wireguard (1.0.20220627-1) ... Setting up wireguard (1.0.20220627-1) ... If there is no space available If additional storage space is needed, you can safely delete the backup system image (not the currently running firmware).\n1 delete system image You can check if wireguard is installed by running:\n1 wg version Output log:\n1 2 user@ER-X:~$ wg version wireguard-tools v1.0.20210914 - https://git.zx2c4.com/wireguard-tools/ Step 2. Key Creation Confirm working directory\n1 pwd Generate Server Keys Create folder for your server keys You can create it in the /config directory to preserve your files during upgrades, and to make it easier during backups.\n1 cd /config Create a folder wireguard, then create another folder for server_keys\n1 2 mkdir wireguard; cd wireguard mkdir server_keys; cd server_keys Generate a key pair for the Wireguard server\n1 wg genkey | tee privatekey | wg pubkey \u0026gt; publickey Note your public and private key for the next configuration steps.\n1 cat publickey privatekey Generate Client Keys Move to wireguard directory.\n1 cd /config/wireguard Create folder wg_clients\n1 mkdir wg_clients ; cd wg_clients Create folder for client01\n1 mkdir client01 ; cd client01 Generate client keys.\n1 wg genkey | tee privatekey | wg pubkey \u0026gt; publickey Note your public and private key for the next configuration steps.\n1 cat publickey privatekey Example output:\n1 2 3 user@ER-X:~$ cat privatekey publickey sAoqK3dXpc2UbOn2LWb/MMcHTKtU0nqHjDQiXqNcyHs= Bf6LBfuoRDRbO4EJ+tawJXu6qu5BOWaXGK0V+uVRC3Q= Step 3. wg0 Interface Configuration Enter configure mode\n1 configure Set the location of the server\u0026rsquo;s private-key, previously generated\n1 set interfaces wireguard wg0 private-key \u0026lt;server-private-key-here\u0026gt; Create the Gateway IP for the VPN and the subnet This subnet can be any private IP range, though make sure to check for conflicts\n1 set interfaces wireguard wg0 address 10.0.0.1/32 Create entries in the route table for the VPN subnet\n1 set interfaces wireguard wg0 route-allowed-ips true Set the UDP port for WG (that peers will use) WireGuard default port is 51820, but can be changed to any port\n1 set interfaces wireguard wg0 listen-port 51820 Save\n1 commit ; save Step 4. Adding peers to the wg0 Interface Adding Client 01 Note: make sure you are in configure mode.\n1 set interfaces wireguard wg0 peer \u0026lt;public-key-here\u0026gt; 1 set interfaces wireguard wg0 peer \u0026lt;public-key-here\u0026gt; allowed-ips 10.0.0.5/32 1 set interfaces wireguard wg0 peer \u0026lt;public-key-here\u0026gt; description client01 Adding Additional Clients When adding additional peers, repeat the steps above, make sure to update allowed-ips and description for the new clients.\n1 set interfaces wireguard wg0 peer \u0026lt;public-key-here\u0026gt; 1 set interfaces wireguard wg0 peer \u0026lt;public-key-here\u0026gt; allowed-ips 10.0.0.6/32 1 set interfaces wireguard wg0 peer \u0026lt;public-key-here\u0026gt; description client02 Save\n1 commit ; save Step 5. Create firewall rules for WireGuard Create an accept rule in WAN_LOCAL to accept all incoming UDP connections from port 51820 (or any port of your choice).\n1 2 3 4 set firewall name WAN_LOCAL rule 50 action accept set firewall name WAN_LOCAL rule 50 protocol udp set firewall name WAN_LOCAL rule 50 destination port 51820 set firewall name WAN_LOCAL rule 50 description \u0026#39;WireGuard\u0026#39; Save\n1 commit ; save Once this is done, your wg0 interface and firewall configuration should look something like this.\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 user@ER-X$ show configuration wireguard wg0 { address 10.0.0.1/32 listen-port 51820 peer Bf6LBfuoRDRbO4EJ+tawJXu6qu5BOWaXGK0V+uVRC3Q= { allowed-ips 10.0.0.6/32 description client02 } peer Kf6LBfuoRDRbO4EJ+tawJXu6qu5BOWaXGK0V+uVRC3Q= { allowed-ips 10.0.0.5/32 description client01 } } private-key **************** route-allowed-ips true } } rule 50 { action accept description WireGuard destination { port 51820 } log enable protocol udp source { } } } } Step 6. Constructing the Config on the peer side Config File (.conf) Create a file on the peer, with the file extension as .conf\nThe peer side needs a few pieces of information to create the tunnel:\nThe server’s public key The server’s endpoint (public IP address, or DNS record) The peer’s private key The peer’s IP address in the VPN subnet (the allowed IPs value set on the server) Therefore, the previously generated client01 private-key and the server-public-key, should be copied to the peer device.\nThe configuration should look something like the one below:\nExample Client 01 1 2 3 4 5 6 7 8 9 10 [Interface] PrivateKey = \u0026lt;private-key-here\u0026gt; ListenPort = 51820 Address = 10.0.0.5/32 DNS = \u0026lt;any dns\u0026gt;, 9.9.9.9 [Peer] PublicKey = \u0026lt;public-key-here\u0026gt; AllowedIPs = 0.0.0.0/0 Endpoint = \u0026lt;your-public-ip-or-dynamic-dns-hostname\u0026gt;:51820 Example Client 02 1 2 3 4 5 6 7 8 9 10 [Interface] PrivateKey = \u0026lt;private-key-here\u0026gt; ListenPort = 51820 Address = 10.0.0.6/32 DNS = \u0026lt;any dns\u0026gt;, 9.9.9.9 [Peer] PublicKey = \u0026lt;public-key-here\u0026gt; AllowedIPs = 0.0.0.0/0 Endpoint = \u0026lt;your-public-ip-or-dynamic-dns-hostname\u0026gt;:51820 Once the .conf file is created, you can import that into the peer/device of your choice.\nTo bring up your tunnel, you can use the wg-quick command.\n1 wg-quick up client01.conf Run wg show on your peer to verify you are connected to the endpoint.\n1 2 3 4 5 6 7 8 9 10 11 12 13 user@PC$ wg show interface: client01 public key: \u0026lt;private-key\u0026gt; private key: (hidden) listening port: 51820 fwmark: 0xca6c peer: \u0026lt;peer-key\u0026gt; endpoint: xx.xx.xx.xx:51820 allowed ips: 0.0.0.0/0 latest handshake: 11 seconds ago transfer: 3.11 MiB received, 6.92 MiB sent Step 7. Save WireGuard Keys and Configuration Files Once the above configuration is made, you can easily save the config by running a backup from the Edgerouter\u0026rsquo;s GUI.\nNavigate to the System tab in the bottom-left of the GUI to download the backup configuration archive. System \u0026gt; Configuration Management \u0026amp; Device Maintenance \u0026gt; Back Up Config\nDownload the backup config file by clicking on the Download button.\nThe EdgeRouter will prompt you to save the archive on your computer.\nYou can then extract this file on your local machine, and in the /config directory, you\u0026rsquo;ll find the wireguard public and private keys you generated earlier.\nQuick Script Warning, the following script is not guaranteed to work, you may need to modify it according to your specific platform/version. Use at your own risk.\nDetermine shell with echo $SHELL\n1 2 user@ER-X:~$ echo $SHELL /bin/vbash EdgeOS comes with vi, you can use that to create the script.\n1 2 user@ER-X:~$ touch wg-setup.sh user@ER-X:~$ vi wg-setup.sh NOTE: Make sure to modify your $SHELL in case it differs, for EdgeOS, it will usually be #!/bin/vbash\nPaste the following:\n1 2 3 4 5 6 7 8 #!/bin/vbash /bin/ip link add dev wg0 type wireguard /bin/ip addr add 10.0.0.1/32 dev wg0 /usr/bin/sudo /usr/bin/wg setconf wg0 /home/$USER/wg0.conf /bin/ip link set up dev wg0 /bin/ip route add 10.0.0.1/32 dev wg0 /usr/bin/sudo /sbin/ifconfig wg0 mtu 1300 Make executable\n1 chmod +x wg-setup.sh Run\n1 ./wg-setup.sh Sources:\nhttps://github.com/WireGuard/wireguard-vyatta-ubnt/wiki/EdgeOS-and-Unifi-Gateway https://www.wireguard.com/quickstart/ https://blog.usman.network/posts/wireguard-vpn-on-a-ubiquiti-edgerouter/ ","permalink":"https://netsparse.dev/posts/2023-03/setup-wireguard-edgerouter/","summary":"WireGuard is a fast and secure VPN protocol that uses state-of-the-art cryptography. It is designed to be easy to implement and manage, and has a minimal attack surface. Its simplicity and efficiency make it well-suited for use in mobile devices and large-scale deployments.\nNote: Before making any major changes on your EdgeOS router, always make a backup. Refer to the official documentation on how to perform one.\nBreakdown Step 1. Installation Note: The following installation guide was verified working on EdgeOS v2.","title":"Setup WireGuard VPN Server with Ubiquiti Edgerouter X (EdgeOS)"},{"content":"In our previous post, we setup a Pi-hole DNS server to block ads on our local network.\nAlthough the Pi-hole is awesome, unfortunately it only works on our local network, and thus we don\u0026rsquo;t get the same benefits of ad blocking when we leaving the network.\nToday, I\u0026rsquo;ll show you how you can setup NextDNS on your mobile or laptop devices for whenever you need ad blocking on the go.\nOverview NextDNS is a cloud-based, privacy-focused DNS service that allows users to block ads, trackers, and malware across all their devices.\nIt was founded in May 2019 by two French founders, Romain Cointepas and Olivier Poitrey.\nIt works by intercepting DNS queries made by devices on the network and routing them to NextDNS servers (similar to Pi-hole), which then filter and block unwanted content based on various criteria such as malware, phishing, and adult content.\nIt utilizes DNS over HTTPS (DoH), DNS over TLS (DoT), DNS over QUIC (DoQ) and more, which also provide a level of security for your DNS queries.\nYou can define rules for filtering on a per device basis on the setup dashboard.\nNextDNS utilize their own custom DNS servers which you can find on under the Endpoints tab on the Setup Page.\nYou can learn more about the company here.\nSetup Try It Now To get started with NextDNS, you can follow their try it now link which you can use to get started immediately, although to take full advantage of the service and be able to customize it, you\u0026rsquo;ll need to create an account.\nNote: If you use the try it now link, the account will expire in 7 days and is only accessible from the browser you initially set it up from. You\u0026rsquo;ll need to sign in in order to keep your customizations.\nOnce you sign up, you\u0026rsquo;ll be taken to the dashboard, where you can manage your settings and configure your DNS preferences.\nWindows To configure NextDNS on a Windows machine, follow these steps:\nNextDNS App for Windows (Recommended) Download the installer here. After installing, right-click on NextDNS icon in the Systray, then open the Settings. Set \u0026lt;your-nextdns-config-id\u0026gt; as Configuration ID. Right-click on NextDNS icon in the Systray, then click on Enable. Manual Configuration Open the Start menu and type \u0026ldquo;Control Panel.\u0026rdquo; Click on the Control Panel app to open it. Click on \u0026ldquo;Network and Internet\u0026rdquo; and then \u0026ldquo;Network and Sharing Center.\u0026rdquo; Click on \u0026ldquo;Change adapter settings.\u0026rdquo; Right-click on your network adapter and select \u0026ldquo;Properties.\u0026rdquo; Click on \u0026ldquo;Internet Protocol Version 4 (TCP/IPv4)\u0026rdquo; and then click \u0026ldquo;Properties.\u0026rdquo; Click on \u0026ldquo;Use the following DNS server addresses\u0026rdquo; and enter the IP address of the NextDNS server you want to use. You can find the latest IP addresses in the NextDNS dashboard under Setup Guide. Click \u0026ldquo;OK\u0026rdquo; to save your changes. macOS Configuration Profile (Recommended) macOS Big Sur or higher\nUse the Apple Configuration Profile Generator available at apple.nextdns.io.\nApp Store \u003c!DOCTYPE html\u003e Install our official app from the Mac App Store. Click on Preferences in the app status bar menu and go to the Configuration tab. Check Use Custom Configuration and enter \u0026lt;your-nextdns-config-id\u0026gt; as Configuration ID. Enable NextDNS. Manual Configuration To configure NextDNS on a macOS machine, follow these steps:\nClick on the Apple menu and select \u0026ldquo;System Preferences.\u0026rdquo; Click on \u0026ldquo;Network.\u0026rdquo; Select your network connection and click \u0026ldquo;Advanced.\u0026rdquo; Click on the \u0026ldquo;DNS\u0026rdquo; tab. Click on the \u0026ldquo;+\u0026rdquo; button to add a new DNS server. Enter the IP address of the NextDNS server you want to use. You can find the latest IP addresses in the NextDNS dashboard under Setup Guide. Click \u0026ldquo;OK\u0026rdquo; to save your changes. iOS / iPadOS Configuration Profile (Recommended) iOS 14 or higher\nUse the Apple Configuration Profile Generator available at apple.nextdns.io.\nDownload the configuration profile. Open the Settings app. Tap Profile Downloaded. Tap Install in the upper-right corner, and follow the onscreen instructions. App Store \u003c!DOCTYPE html\u003e Install the official app from the App Store. Open the app then go to Settings and toggle \u0026ldquo;Use Custom Configuration\u0026rdquo;. Enter \u0026lt;your-nextdns-id\u0026gt; as Configuration ID. Enable NextDNS. Android Private DNS (Recommended) Android 9 or higher\nGo to Settings → Network \u0026amp; internet → Advanced → Private DNS. Select the Private DNS provider hostname option. Enter \u0026lt;your-nextdns-config-id\u0026gt;.dns.nextdns.io and hit Save. App Store \u003c!DOCTYPE html\u003e NextDNS App for Android\nInstall the official app from the Play Store. In the NextDNS app, enter \u0026lt;your-nextdns-config-id\u0026gt; in Settings → Configuration ID, then connect. Linux systemd-resolved (Recommended) Use the following in /etc/systemd/resolved.conf:\nNote: Make sure to replace \u0026lt;nextdns-id-here\u0026gt; with your Configuration ID.\n1 2 3 4 5 6 [Resolve] DNS=45.90.28.0#\u0026lt;nextdns-id-here\u0026gt;.dns.nextdns.io DNS=2a07:a8c0::#\u0026lt;nextdns-id-here\u0026gt;.dns.nextdns.io DNS=45.90.30.0#\u0026lt;nextdns-id-here\u0026gt;.dns.nextdns.io DNS=2a07:a8c1::#\u0026lt;nextdns-id-here\u0026gt;.dns.nextdns.io DNSOverTLS=yes NextDNS Command-Line Client Run the following command: sh -c \u0026quot;$(curl -sL https://nextdns.io/install) Follow the instructions. Head over to our open-source repository at https://github.com/nextdns/nextdns/wiki for manual installation instructions. Identify Your Devices Follow the instructions below to identify your devices in Analytics and Logs.\nNS-over-TLS/QUIC Prepend the name to the provided domain (the name should only contain a-z, A-Z, 0-9 and -). Use \u0026ndash; for spaces. For \u0026ldquo;John Router\u0026rdquo;, you would use John--Router-\u0026lt;nextdns-config-id\u0026gt;.dns.nextdns.io as your DNS-over-TLS endpoint.\nDNS-over-HTTPS Append the name to the provided URL (the name should be URL encoded). For \u0026ldquo;John\u0026rsquo;s Firefox\u0026rdquo;, you would use https://dns.nextdns.io/\u0026lt;nextdns-config-id\u0026gt;/John's%20Firefox as your DNS-over-HTTPS endpoint.\nApps Enable Send Device Name in the app settings.\nNote Keep in mind that the above setup is only a guideline as of 03-2023.\nThe information may become outdated or changed. Always consult with the latest official documentation from NextDNS on their site, Setup Guide, and their Help Center.\nConclusion NextDNS is a powerful DNS service that offers a range of privacy-focused features to protect your devices from ads, trackers, and malware. By following the steps above, you can easily configure NextDNS on your devices and start enjoying a safer, more secure online experience.\nLearn More NextDNS Wiki (GitHub) NextDNS Help Center NextDNS Privacy Policy Source Code NextDNS and Pi-hole Tools Ping Check Routing Check DNS Leak Test RIPEstat BGP Lookup NextDNS ","permalink":"https://netsparse.dev/posts/2023-03/take-your-ad-blocking-with-you-with-nextdns/","summary":"In our previous post, we setup a Pi-hole DNS server to block ads on our local network.\nAlthough the Pi-hole is awesome, unfortunately it only works on our local network, and thus we don\u0026rsquo;t get the same benefits of ad blocking when we leaving the network.\nToday, I\u0026rsquo;ll show you how you can setup NextDNS on your mobile or laptop devices for whenever you need ad blocking on the go.","title":"Take Your Ad Blocking With You On The Go With NextDNS"},{"content":"Pi-hole is a DNS sinkhole that blocks advertisements, trackers, and other unwanted content from being served to devices on your network.\nIt can be run on a Raspberry Pi or other hardware, but running it in a Docker container has some benefits, such as easier installation and management.\nIf you are also new to Docker, check out my previous post on how to get started with Docker.\nA Bit of History The Pi-hole project was started by Jacob Salmela in 2014 as an open source alternative to AdTrap, which was a device that would block advertisements and tracking domains at the network level.\nSalmela, a former system administrator, was looking for a solution that would block ads and tracking for all devices on his home network, without having to install ad blockers on each individual device.\nThe Pi-hole quickly gained popularity among privacy-conscious users and became a popular tool for blocking ads and tracking domains at the network level.\nToday, the Pi-hole project continues to be maintained and improved by a community of volunteers, with regular updates and new features being added.\nHow It Works DNS When you visit a Website, that site might be trying to load stuff from other domains (such as advertisements). So your computer makes a DNS query to find out the IP address of that resource.\nSince the Pi-hole acts as a DNS server, it can tell your computer that SomeAdDomain.com exists at a fake IP address (usually 0.0.0.0), instead of loading the ad from the real domain, a blank page from the Pi is downloaded, thus “blocking” the ad.\nIf you are new to DNS, here\u0026rsquo;s a quick overview by Fireship.io.\nBenefits Block ads and trackers: Pi-hole blocks ads, trackers, and other unwanted content at the DNS level, so it can be more effective than browser-based ad blockers that only block ads on the sites you visit. Faster browsing: By blocking unwanted content, Pi-hole can speed up browsing and reduce data usage. Network-wide blocking: Pi-hole can be set up to block ads and trackers on all devices on your network, including smartphones, tablets, and smart TVs. Easy to use: Once set up, Pi-hole requires minimal maintenance and can be easily managed through a web interface. Setup One-Step Automated Install Those who want to get started quickly and conveniently may install Pi-hole using the following command:\n1 curl -sSL https://install.pi-hole.net | bash Install with Docker and Docker Compose If you are familiar with Docker and Docker Compose, you can utilize them to setup a Pi-hole in a container.\nCreate Docker Compose File Create a Docker Compose file that defines our Pi-hole container.\nCreate a new file named docker-compose.yml in a new directory and paste the following contents:\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 version: \u0026#39;3\u0026#39; services: pihole: image: pihole/pihole:latest container_name: pihole restart: always environment: TZ: \u0026#39;America/Chicago\u0026#39; WEBPASSWORD: \u0026#39;your_password_here\u0026#39; volumes: - \u0026#39;./etc-pihole/:/etc/pihole/\u0026#39; - \u0026#39;./etc-dnsmasq.d/:/etc/dnsmasq.d/\u0026#39; ports: - \u0026#39;53:53/tcp\u0026#39; - \u0026#39;53:53/udp\u0026#39; - \u0026#39;80:80/tcp\u0026#39; - \u0026#39;443:443/tcp\u0026#39; This Docker Compose file specifies the Pi-hole image, container name, restart policy, environment variables, volumes, DNS servers, and ports.\nYou can customize some of the values in this file, such as the timezone TZ, the web interface password WEBPASSWORD, and the DNS servers.\nThe volumes section specifies the directories where Pi-hole will store its configuration files and blocklists.\nStart Pi-hole Container With the Docker Compose file created, we can start the Pi-hole container by running the following command in the same directory as the docker-compose.yml file:\n1 docker-compose up -d You can learn more about the Docker installation method here\nAccess Pi-hole Web Interface Once the container is running, you can access the Pi-hole web interface by opening a web browser and navigating to http://\u0026lt;ip_address_of_docker_host\u0026gt;\nIf you’re running Docker on your local machine, you can use http://localhost or http://127.0.0.1.\nYou should see the Pi-hole web interface, which allows you to configure Pi-hole, view statistics, and manage blocked domains.\nConfiguration DHCP Settings on Router Before Pi-hole can start blocking ads and trackers, you will need to configure your router to have DHCP clients use Pi-hole as their DNS server, which ensures all devices connected to your network will have content blocked without any further intervention.\nThis will of course vary depending on your router\u0026rsquo;s model and make. Consult with your router manufacturer\u0026rsquo;s guide on how to perform the above.\nIf your router does not support setting the DNS server, you can use Pi-hole\u0026rsquo;s built-in DHCP server; just be sure to disable DHCP on your router first (if it has that feature available).\nManual Device Configuration As a last resort, you can manually set each device to use Pi-hole as its DNS server.\nOnce your devices are using Pi-hole as their DNS server, Pi-hole will start blocking ads and trackers automatically.\nUpdate Pi-hole To update Pi-hole to a newer version, you can simply run the following command:\n1 pihole -up If you setup your Pi-hole with Docker and Docker Compose, run:\n1 2 docker-compose pull docker-compose up -d This will pull the latest version of the Pi-hole image and recreate the container with the new image.\nConclusion Setting up a Pi-hole Docker container using Docker Compose is an easy and convenient way to block ads and trackers on your network. With Pi-hole, you can speed up browsing, reduce data usage, and block unwanted content at the DNS level. Docker Compose makes it easy to manage and deploy Pi-hole, and the web interface allows you to configure Pi-hole and view statistics.\nLearn More Official Documentation FAQ GitHub About Docker Guide ","permalink":"https://netsparse.dev/posts/2023-03/pihole-dns-with-docker/","summary":"Pi-hole is a DNS sinkhole that blocks advertisements, trackers, and other unwanted content from being served to devices on your network.\nIt can be run on a Raspberry Pi or other hardware, but running it in a Docker container has some benefits, such as easier installation and management.\nIf you are also new to Docker, check out my previous post on how to get started with Docker.\nA Bit of History The Pi-hole project was started by Jacob Salmela in 2014 as an open source alternative to AdTrap, which was a device that would block advertisements and tracking domains at the network level.","title":"Block Ads for All Your Devices with Pi-Hole DNS and Docker"},{"content":"Diagrams.net (or Draw.io) is a free and open source cross-platform graph drawing software developed in HTML5 and JavaScript by UK-based JGraph Ltd in 2000.\nIts interface can be used to create diagrams such as flowcharts, network diagrams, organizational charts, or any other type of diagram.\nIt is a useful alternative to more commercial tools like Microsoft Visio or Lucidchart.\nGetting Started You can immediately start by heading over to the web application at app.diagrams.net. There you can create and export your diagrams through the included web interface.\nDesktop apps are available for Windows and Mac OS, which you can download here.\nThere are also integrations with other platforms and applications, including Atlassian Confluence Cloud and Jira Cloud, Google applications, GitHub and Microsoft applications.\nWorkflow Online Whiteboard The web based editor at diagrams.net gives you an easy-to-use online whiteboard to quickly note ideas and create graphs.\nBelow is a general overview of the layout of the editor and some of the elements.\nChoosing the Right Template To choose a template, click on the File menu and select New.\nYou\u0026rsquo;ll be prompted with a list of templates, if you want a blank diagram, select it and then select Insert.\nIf you wish to select a different template, you can navigate back and select the template of your choosing.\nAdding Shapes and Text To add a shape, simply click on the shape tool in the toolbar and drag the shape onto the canvas. You can also utilize the shape library and search for a specific shape.\nThe shape library search feature looks for shape names that match or are similar to your search term.\nAt the top of the left panel, type your search term and press Enter. Click More Results to see more matching shapes. To add text to your diagram, click on the text tool in the toolbar and click on the canvas where you want to add the text.\nYou can also select Arrange \u0026gt; Insert \u0026gt; Text to insert a basic text shape. Or click the + icon in the toolbar, then select Text.\nConnecting Shapes Click on the connector tool in the toolbar and drag the connector from one shape to another. You can customize the connector by changing its style, color, and thickness.\nYou can also connect shapes by cloning them, this will add another shape and automatically connect them.\nYou can learn more about the different ways to connect shapes here.\nAdding Images and Other Elements To add an image, simply click on the Image tool in the toolbar and select the image you want to add. You can then resize and position the image as needed.\nJPEG, PNG, and SVG images can all be inserted into the diagram editor with drag and drop or via the menu.\nImage files in diagrams work in the same way as in documents - you can resize, rotate and flip them as a single image, but you can’t resize any components within the image.\nAlternatively, you can insert from the menu:\nSelect Arrange \u0026gt; Insert \u0026gt; Image or\nClick the + icon in the toolbar, then select Image. Saving and Exporting Your Diagram Once you have finished creating your diagram, you can save it by clicking on the File menu and selecting Save.\nYou can then export your diagram as an image, PDF, URL, or other format by clicking on the Export as menu and selecting the format you want to use.\nRun Your Own Diagramming Server with Docker There are many reasons that a SaaS application is not the right choice and companies prefer to run the software in their own environment, where all of the data and applications are kept behind a firewall for maximum security.\nDraw.io Docker image\nThe draw.io Docker image is based on Tomcat to support reverse proxies, and is kept up to date with the production draw.io running on app.diagrams.net.\nInstall and run the Docker platform on your server or desktop machine. Run the draw.io Docker container: 1 docker run -it --rm --name=\u0026#34;draw\u0026#34; -p 8080:8080 -p 8443:8443 jgraph/drawio Note: Use the DRAWIO_* environment variables listed in docker-entrypoint.sh in the main directory to set up certificates and access to an SSL keystore mount.\nFor example, a configured command will look similar to:\n1 docker run -it -m1g -e LETS_ENCRYPT_ENABLED=true -e PUBLIC_DNS=drawio.example.com --rm --name=\u0026#34;draw\u0026#34; -p 80:80 -p 443:8443 jgraph/drawio For more information on setup and configuration options, refer to the draw.io Docker image page on DockerHub.\nConclusion Diagrams.net is a powerful and versatile tool for creating beautiful diagrams and drawings.\nWith its wide range of templates and intuitive interface, you can quickly create professional-looking diagrams and drawings that are sure to impress.\nLearn More Getting Started Guide Documentation Features Blog About JGraph Ltd Docker Guide Project GitHub Docker Hub ","permalink":"https://netsparse.dev/posts/2023-02/create-awesome-diagrams-and-graphs-for-your-docs/","summary":"Diagrams.net (or Draw.io) is a free and open source cross-platform graph drawing software developed in HTML5 and JavaScript by UK-based JGraph Ltd in 2000.\nIts interface can be used to create diagrams such as flowcharts, network diagrams, organizational charts, or any other type of diagram.\nIt is a useful alternative to more commercial tools like Microsoft Visio or Lucidchart.\nGetting Started You can immediately start by heading over to the web application at app.","title":"Awesome Diagrams and Graphs for Your Documentation"},{"content":"Obsidian is a powerful note-taking tool that allows you to create, organize, and link your notes in a way that makes sense to you. It\u0026rsquo;s a flexible and customizable tool that can be used for a variety of purposes, from personal journaling to project management.\nGetting Started Obsidian is available for Windows, Mac OS, Linux, Android, and iOS. Download the installer and install it on your system.\nCreate A Vault To create a new empty vault from the vault switcher:\nTo the right of Create new vault, click Create. In Vault name, enter the name of your vault. Click Browse to select where your new vault will be created. Click Create. Create a Note To create a new note, simply click on the New Note button in the left-hand pane.\nFormat Your Note Obsidian also supports Markdown — a markup language for adding formatting to plain text files.\nCopy and paste the following text at the top of the Obsidian note:\n1 # A second brain, for you, forever. The hashtag (#) turns a row of text into a heading.\nIn your note, select the text \u0026ldquo;knowledge base\u0026rdquo; and press Ctrl+B (or Cmd+B on macOS) to make it bold.\nCheck out the markdown section below:\nLink Your Notes One of the most powerful features of Obsidian is its ability to link your notes together.\nThis allows you to create a web of interconnected notes that can help you see relationships and patterns between different ideas.\nTo link your notes together, simply use double square brackets around the title of the note you want to link to.\nFor example, if you have a note titled Project Planning, and you want to link to it from another note, you would type [[Project Planning]] in the text of the second note.\nObsidian Notes will automatically create a link to the Project Planning note, and you can click on this link to quickly navigate to that note.\nYou can also see all the notes that link to a particular note by clicking on the Backlinks button in the left-hand pane.\nCreating Maps Once you have linked your notes together, you can start creating maps that show the relationships between different notes.\nObsidian has a built-in graph view that allows you to create visual maps of your notes and their connections.\nTo create a map, simply click on the Graph View button in the left-hand pane.\nYou can then drag and drop notes to rearrange them and see how they are connected. You can also click on a note to see all the notes that link to it and from it.\nIt also allows you to customize your maps by changing the color and shape of notes, as well as adding labels and tags to notes.\nMarkdown Markdown is a simple and lightweight formatting language that you can use to add formatting and structure to your plain text documents. You can easily create headings, lists, bold and italic text, and links, among other things.\nIt uses a series of special characters and symbols to indicate formatting.\nFor example, you can create a heading by starting a line with one or more hash symbols #, or make text bold by surrounding it with double asterisks **.\n1 2 3 4 5 6 # This is a heading 1 ## This is a heading 2 ### This is a heading 3 #### This is a heading 4 **Bold Text** The great thing about it is that it is very easy to read and write, and it can be used with many different types of software and applications. It is also highly portable, meaning that you can easily move your Markdown-formatted documents between different platforms and devices without losing any of the formatting.\nTo learn more about how to format your notes using Markdown within Obsidian, refer to Basic formatting syntax.\nConclusion Obsidian is a powerful and flexible note-taking tool that can help you organize your thoughts and ideas in a way that makes sense to you.\nBy linking your notes together and creating maps, you can create a web of interconnected ideas that can help you see relationships and patterns that you might otherwise miss.\nLearn More Obsidian Documentation Command Palette Formatting Syntax ","permalink":"https://netsparse.dev/posts/2023-02/awesome-notes-with-obsidian/","summary":"Obsidian is a powerful note-taking tool that allows you to create, organize, and link your notes in a way that makes sense to you. It\u0026rsquo;s a flexible and customizable tool that can be used for a variety of purposes, from personal journaling to project management.\nGetting Started Obsidian is available for Windows, Mac OS, Linux, Android, and iOS. Download the installer and install it on your system.\nCreate A Vault To create a new empty vault from the vault switcher:","title":"Create Awesome Notes With Obsidian"},{"content":"Portainer is a simple and open-source web application for managing Docker containers. It lets users easily deploy and manage Docker-based applications through a web interface, without needing to use the command-line tools.\nIt supports various Docker environments and provides role-based access control, making it suitable for both individuals and organizations. Portainer is also highly extensible, allowing users to add more functionalities and integrate with other tools and platforms.\nDeployment Install Portainer Community Edition (CE) First, create the volume that Portainer Server will use to store its database:\n1 docker volume create portainer_data Then, download and install the Portainer Server container:\n1 docker run -d -p 8000:8000 -p 9443:9443 --name portainer --restart=always -v /var/run/docker.sock:/var/run/docker.sock -v portainer_data:/data portainer/portainer-ce:latest You can read more about the installation process on Portainer\u0026rsquo;s documentation.\nAccessing Portainer Once you have installed Portainer, you can access it by opening a web browser and navigating to https://your-machine's-ip-address:9443\nFrom there, you will be prompted to set up an admin account and select the environment you want to manage.\nOnce setup, you should see the main dashboard:\nManaging Containers with Portainer Once you have set up your Portainer account, you can start managing your Docker containers.\nPortainer provides an easy-to-use web interface that allows you to view all your containers, their status, and resource usage.\nFor example, you can see the individual containers running from my other Docker host.\nTo manage a container, simply click on it in the Portainer interface.\nFrom there, you can start, stop, or restart the container, view its logs, and manage its settings.\nPortainer also allows you to manage multiple containers at once, making it easy to perform bulk operations.\nMonitoring Container Performance with Portainer Portainer also provides a powerful monitoring tool that allows you to monitor the performance of your Docker containers in real-time.\nThe monitoring tool provides detailed information on CPU usage, memory usage, network traffic, and more, allowing you to identify performance issues and optimize your containers for better performance.\nTo access the monitoring tool, simply click on a container in the Portainer interface and select the \u0026ldquo;Statistics\u0026rdquo; tab.\nFrom there, you can view detailed performance metrics and even set up alerts to notify you when certain thresholds are exceeded.\nConclusion Portainer is a powerful and flexible tool for managing and monitoring Docker containers.\nBy installing Portainer and using its web interface, you can easily manage your Docker containers and clusters, view detailed performance metrics, and optimize your containers for better performance.\nWith its easy-to-use interface and powerful monitoring tool, Portainer is a must-have tool for anyone working with Docker containers.\nLearn More Official Documentation Knowledge Base Concepts \u0026amp; Architecture Portainer.io ","permalink":"https://netsparse.dev/posts/2023-02/manage-your-docker-env-with-portainer/","summary":"Portainer is a simple and open-source web application for managing Docker containers. It lets users easily deploy and manage Docker-based applications through a web interface, without needing to use the command-line tools.\nIt supports various Docker environments and provides role-based access control, making it suitable for both individuals and organizations. Portainer is also highly extensible, allowing users to add more functionalities and integrate with other tools and platforms.\nDeployment Install Portainer Community Edition (CE) First, create the volume that Portainer Server will use to store its database:","title":"Manage Your Docker Environment With Portainer"},{"content":"One awesome feature in Proxmox VE is to run an LXC (Linux Container) directly from the web interface.\nA quick machine can be spun up that works and acts just like a regular full-blown Linux Virtual machine.\nThe downside to this is we are limited to what resources you provide the VM, not the resources that are given to an LXC (which is essentially the maximum of the host system).\nSide Note\nThis requires running an LXC as Unprivileged. To learn more about what this means, please refer to the Proxmox documentation, or check out the official LXC docs here.\nPreparing Proxmox Note: This will need to be done on each Proxmox host you have, so each command will need to be done for how ever many hosts you have Enable Kernel Modules\nThe overlay and aufs kernel modules need to be enabled to support running containers:\n1 echo -e \u0026#34;overlay\\naufs\u0026#34; \u0026gt;\u0026gt; /etc/modules-load.d/modules.conf Please note that the aufs module is deprecated as of Proxmox VE 7.0 This CAN be explicitly enabled, but it won’t do anything Reboot host For the changes to take effect, reboot the host\nCheck changes Upon starting back up, run the following:\n1 lsmod | grep -E \u0026#39;over This should return something like:\n1 overlay 131072 3 Create an unprivileged container The creation process is pretty standard, and what you’re used to. But there are a few changes you will need to make along the way:\nOn the Proxmox GUI, click the Create CT button Make sure you have “Unprivileged container” checked For the rest of the setup, give it your preferred configuration Make sure you don’t start the container upon creation Edit container’s features Click on your new container\nGo to Options Double-click on the Features row Ensure that the following are checked: keyctl nesting Click OK Start the container Install Docker Head over to Docker’s docs, and find the steps to install docker for your distro.\nOnce all set up, test out the installation with docker run hello-world and it should be working!\nThis guide is based from Quinn Henry\u0026rsquo;s blog over at https://quibtech.com\n","permalink":"https://netsparse.dev/posts/2023-02/docker-on-lxc/","summary":"\u003cp\u003eOne awesome feature in Proxmox VE is to run an LXC (Linux Container) directly from the web interface.\u003c/p\u003e","title":"Running Docker containers in a Proxmox LXC container"},{"content":"Docker and Docker Compose are powerful tools that allow you to run and manage applications in containers, making it easy to set up and run applications on any machine, whether it be a laptop, desktop or server.\nHere\u0026rsquo;s a quick overview from Fireship.io.\nOverview Docker is a platform that enables developers to create, deploy, and run applications in containers.\nContainers are lightweight, portable, and self-contained units of software that can run virtually anywhere.\nWith Docker, developers can package an application and its dependencies into a single container that can run on any system that has Docker installed.\nThe isolation and security allows you to run many containers simultaneously on a given host.\nComponents Dockerfile A Dockerfile is a text file that contains instructions for building a Docker image. It specifies the base image to use, the commands to run to set up the environment, and any additional configuration or customization needed.\nOnce the Dockerfile is created, it can be used to build a Docker image that can then be used to run container instances.\nHere\u0026rsquo;s an example of a simple Dockerfile that sets up a Python environment with Flask:\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 # Use an official Python runtime as a parent image FROM python:3.8-slim-buster # Set the working directory to /app WORKDIR /app # Copy the current directory contents into the container at /app COPY . /app # Install any needed packages specified in requirements.txt RUN pip install --trusted-host pypi.python.org -r requirements.txt # Make port 80 available to the world outside this container EXPOSE 80 # Define environment variable ENV NAME World # Run app.py when the container launches CMD [\u0026#34;python\u0026#34;, \u0026#34;app.py\u0026#34;] Another example you can take a look at is Pi-hole\u0026rsquo;s Dockerfile\nImages A Docker image is a snapshot of an application and its dependencies, which can be used to run one or more containers.\nImages are created from Dockerfiles and can be stored in a registry.\nImages are lightweight, portable, and provide a consistent environment for running applications.\nDocker Compose Docker Compose is a tool that enables you to define and run multi-container Docker applications.\nWith Docker Compose, you can define your application\u0026rsquo;s services, networks, and volumes in a single YAML file, making it easy to manage your application\u0026rsquo;s components.\nHere\u0026rsquo;s a general outline of a docker-compose.yml.\n1 2 3 4 5 6 7 8 9 10 version: \u0026#34;3\u0026#34; services: \u0026lt;service_name\u0026gt;: image: \u0026lt;image_name\u0026gt;:\u0026lt;tag\u0026gt; ports: - \u0026#34;\u0026lt;host_port\u0026gt;:\u0026lt;container_port\u0026gt;\u0026#34; volumes: - \u0026#34;\u0026lt;host_path\u0026gt;:\u0026lt;container_path\u0026gt;\u0026#34; environment: - \u0026lt;key\u0026gt;=\u0026lt;value\u0026gt; Getting Started Docker Desktop Docker provides Docker Desktop for Windows, macOS, and Linux. Which provides a GUI environment to manage your containers without relying entirely on the CLI.\nDocker Engine If you wish to utilize just the Docker Engine and CLI, download the engine here for your given platform.\nManage Docker as a non-root user The Docker daemon binds to a Unix socket, not a TCP port. By default it’s the root user that owns the Unix socket, and other users can only access it using sudo. The Docker daemon always runs as the root user.\nIf you don’t want to preface the docker command with sudo, create a Unix group called docker and add users to it.\nWhen the Docker daemon starts, it creates a Unix socket accessible by members of the docker group.\nOn some Linux distributions, the system automatically creates this group when installing Docker Engine using a package manager. In that case, there is no need for you to manually create the group.\nTo create the docker group and add your user:\nCreate the docker group.\n1 sudo groupadd docker Add your user to the docker group.\n1 sudo usermod -aG docker $USER Log out and log back in so that your group membership is re-evaluated.\nRegistry (Docker Hub) To run a container, you first need to find an image for the container you want to run.\nDocker Hub is a popular repository of Docker images, you can search Docker Hub for an image that meets your needs.\nDocker Run Once you have found an image, you can use the docker run command to start a container from that image.\nFor example, to run an instance of the nginx web server, you can run the following command:\n1 docker run -d -p 80:80 nginx This command starts a container from the nginx image, maps port 80 on the host to port 80 in the container, and runs the container in the background (-d).\nYou can access the container from your browser at localhost. You\u0026rsquo;ll then be greeted with the default \u0026ldquo;Welcome to nginx!\u0026rdquo; message.\nDocker Compose Docker Compose] is typically installed as part of the Docker Desktop installation on Windows and macOS. On Linux, you can install Docker Compose using your distribution\u0026rsquo;s package manager or by downloading directly from the Docker website.\nOnce you have Docker Compose installed, you can create a docker-compose.yml file to define your application\u0026rsquo;s services, networks, and volumes. Here is an example docker-compose.yml file that defines a simple web application with a web server and a database:\n1 2 3 4 5 6 7 8 9 10 version: \u0026#39;3\u0026#39; services: web: image: nginx ports: - \u0026#34;80:80\u0026#34; db: image: mysql environment: MYSQL_ROOT_PASSWORD: password This docker-compose.yml file defines two services: web and db.\nThe web service runs an instance of the nginx web server, and maps port 80 on the host to port 80 in the container.\nThe db service runs an instance of the MySQL database server and sets the root password to password.\nTo start the application, you can run the following command:\n1 docker-compose up -d This command starts the application in the background (-d) using the configuration in the docker-compose.yml file.\nVersioning Docker Compose can also be used with version control systems like Git to help manage, deploy, and revert changes of multi-container Docker applications.\nConclusion Docker and Docker Compose are powerful tools that enable you to easily run and manage applications in containers.\nWith Docker, you can package your application and its dependencies into a single container that can run on any system.\nWith Docker Compose, you can define and run multi-container applications using a single configuration file.\nLearn More Official Documentation Docker Overview Reference Documentation CLI Reference Alex Ellis\u0026rsquo; Blog Alex Ellis\u0026rsquo; Hands-on Docker Guide Play With Docker Classroom Veggiemonk GitHub Awesome-Docker ","permalink":"https://netsparse.dev/posts/2023-02/get-started-with-docker/","summary":"Docker and Docker Compose are powerful tools that allow you to run and manage applications in containers, making it easy to set up and run applications on any machine, whether it be a laptop, desktop or server.\nHere\u0026rsquo;s a quick overview from Fireship.io.\nOverview Docker is a platform that enables developers to create, deploy, and run applications in containers.\nContainers are lightweight, portable, and self-contained units of software that can run virtually anywhere.","title":"Get Started with Docker"},{"content":"Proxmox is a powerful, open-source virtualization management platform that allows you to create and manage virtual machines (VMs) and containers on a single server. It is a popular choice for home labbing, where enthusiasts use it to create and test different configurations of operating systems, applications, and network setups.\nIn this article, I\u0026rsquo;ll guide you through the steps required to set up a Proxmox server for home labbing.\nRequirements A 64-bit CPU with Intel VT/AMD-V virtualization support At least 4GB of RAM (8GB or more is recommended) At least 16GB of storage space for the operating system and Proxmox installation At least one Ethernet port for network connectivity Setup Download and Install Proxmox Head over to the Downloads section on Proxmox\u0026rsquo;s site and download the installation ISO.\nOnce you\u0026rsquo;ve downloaded the ISO file, create a bootable USB drive using a tool like Rufus or Etcher.\nNext, boot your server from the installation media and follow the prompts to install Proxmox.\nYou\u0026rsquo;ll need to configure network settings, disk partitioning, and user accounts during the installation process.\nWeb Interface After installing Proxmox, you should be able to access the Proxmox web interface by navigating to https://\u0026lt;your-server's-IP-address\u0026gt;:8006 in your web browser.\nLog in with the root username and the password you created during the installation process.\nClick on the \u0026ldquo;Datacenter\u0026rdquo; node in the left sidebar, you should now be able to see an overview of your node.\nWorkflow Create Virtual Machines and Containers To create a virtual machine, click on the Create VM button in the Proxmox web interface.\nYou\u0026rsquo;ll need to provide details about the virtual machine, including the operating system, disk size, and memory allocation.\nYou can also configure network settings and attach ISO images or virtual disks to the virtual machine.\nSimilarly, to create a container, click on the Create CT button in the Proxmox web interface.\nLinux containers (LXC) are lightweight and use fewer resources than virtual machines. Proxmox utilizes LXC for container management.\nManage Virtual Machines and Containers From the web interface, you can start, stop, and delete virtual machines and containers, as well as view their resource usage and network statistics.\nBackups You can also create backups of your virtual machines and containers, either manually or automatically. Backups are always full backups - containing the VM/CT configuration and all data.\nBackups can be started via the GUI or via the vzdump command line tool.\nCLI Examples: Simply dump guest 777 - no snapshot, just archive the guest private area and configuration files to the default dump directory (usually /var/lib/vz/dump/).\n1 vzdump 777 Use rsync and suspend/resume to create a snapshot (minimal downtime).\n1 vzdump 777 --mode suspend Backup all guest systems and send notification mails to root and admin.\n1 vzdump --all --mode suspend --mailto root --mailto admin Use snapshot mode (no downtime) and non-default dump directory.\n1 vzdump 777 --dumpdir /mnt/backup --mode snapshot Backup more than one guest (selectively)\n1 vzdump 101 102 103 --mailto root Backup all guests excluding 101 and 102\n1 vzdump --mode suspend --exclude 101,102 Restore a container to a new CT 600\n1 pct restore 600 /mnt/backup/vzdump-lxc-777.tar Restore a QemuServer VM to VM 601\n1 qmrestore /mnt/backup/vzdump-qemu-888.vma 601 Clone an existing container 101 to a new container 300 with a 4GB root file system, using pipes\n1 vzdump 101 --stdout | pct restore --rootfs 4 300 - Remove Subscription Notice To get rid of the message, open a shell under the root user and type in the snippet below.\n1 sed -Ezi.bak \u0026#34;s/(Ext.Msg.show\\(\\{\\s+title: gettext\\(\u0026#39;No valid sub)/void\\(\\{ \\/\\/\\1/g\u0026#34; /usr/share/javascript/proxmox-widget-toolkit/proxmoxlib.js \u0026amp;\u0026amp; systemctl restart pveproxy.service Similar VM Platforms and Software VMWare ESXi An enterprise-class, type-1 hypervisor developed by VMware for deploying and serving virtual machines.\nKVM (Kernel-based Virtual Machine) KVM is a popular open-source virtualization solution for Linux that provides a type 1 hypervisor and supports running multiple virtual machines on a single physical server.\nIt is currently the underlying platform that powers Proxmox\u0026rsquo;s virtual machine functionality.\nQEMU (Quick EMUlator) A generic and open source machine emulator and virtualizer.\nIt can also leverage KVM to run VMs at near native speed.\nMicrosoft Hyper-V Hyper-V is a type 1 hypervisor that is included with the Windows Server operating system.\nOracle VirtualBox VirtualBox is a popular open-source virtualization solution that can run on a variety of operating systems, including Windows, Linux, and MacOS.\nCitrix Hypervisor (formely XenServer) Citrix Hypervisor is a type 1 hypervisor that provides similar virtualization capabilities and is designed for enterprise use.\nVMware Workstation VMware Workstation is a type 2 hypervisor that runs on top of an existing operating system.\nEach of these virtualization platforms have their own strengths and weaknesses, the best choice will depend on the specific needs of the user or organization.\nConclusion Setting up a Proxmox server for home labbing is a great way to experiment with different configurations of operating systems, applications, and network setups.\nWith Proxmox, you can create and manage virtual machines and containers on a single server, without the need for additional hardware.\nLearn More Official Docs \u0026amp; Manuals Proxmox Getting Started Guide Proxmox Tutorial Phoenixnap ","permalink":"https://netsparse.dev/posts/2023-02/setup-a-vm-server/","summary":"Proxmox is a powerful, open-source virtualization management platform that allows you to create and manage virtual machines (VMs) and containers on a single server. It is a popular choice for home labbing, where enthusiasts use it to create and test different configurations of operating systems, applications, and network setups.\nIn this article, I\u0026rsquo;ll guide you through the steps required to set up a Proxmox server for home labbing.\nRequirements A 64-bit CPU with Intel VT/AMD-V virtualization support At least 4GB of RAM (8GB or more is recommended) At least 16GB of storage space for the operating system and Proxmox installation At least one Ethernet port for network connectivity Setup Download and Install Proxmox Head over to the Downloads section on Proxmox\u0026rsquo;s site and download the installation ISO.","title":"Setup a VM Server with Proxmox VE"},{"content":"A homelab is a place where you can experiment, learn, and grow in ways you never thought possible. You can build yourself an environment to test and tinker with some technologies you may be interested in, practice setting up networks and operating systems, and explore cutting-edge technologies.\nWith a homelab, you\u0026rsquo;re not just reading about the technology - you\u0026rsquo;re experiencing it firsthand. It\u0026rsquo;s a space where you can make mistakes and learn from them, without the fear of potentially damaging a production environment.\nStarting a homelab is about taking control of your own learning journey. It\u0026rsquo;s about pursuing your interests and passions, and gaining skills that are in demand in today\u0026rsquo;s job market.\nIt\u0026rsquo;s about unlocking a world of new possibilities and opportunities, so that you can one day take those skillsets with you anywhere you go.\nPractical Reasons Gain Practical Experience One of the primary reasons to set up an homelab is to gain practical experience. By setting up a lab, you can experiment with different hardware and software configurations, test new skills and techniques, and simulate real-world scenarios. This hands-on experience is invaluable for building your skills and knowledge and can help you stand out in the job market.\nLearn New Skills Setting up an homelab is also a great way to learn new skills. Whether you\u0026rsquo;re interested in networking, cybersecurity, programming, or another area of IT, you can use your lab to practice and learn new skills. You can also experiment with new software or tools that you might not have access to in a traditional classroom or workplace environment.\nStay Up-to-Date with Technology Technology is constantly evolving, and it can be challenging to keep up with the latest trends and tools. By setting up an homelab, you can stay up-to-date with the latest technology and trends. You can experiment with new tools and technologies and learn how they work in a safe and controlled environment.\nPrepare for Certifications If you\u0026rsquo;re interested in pursuing IT certifications, setting up an homelab can be a valuable tool for preparing for exams. Many certifications require hands-on experience with specific hardware and software, and a lab can provide you with the experience you need to pass the exam.\nSave Money Finally, setting up an IT homelab can be a cost-effective way to gain practical experience and learn new skills. By using virtualization software, you can run multiple operating systems on a single computer, which can save you money on hardware costs. You can also experiment with open-source software, which is often free, rather than purchasing expensive commercial software.\nMy Lab You know I can\u0026rsquo;t speak on this topic if I don\u0026rsquo;t have a homelab myself, although a work in progress, I definitely love what I\u0026rsquo;ve managed to build and learn, I\u0026rsquo;m definitely learning everyday, and the lab is also growing alongside me.\nYou can check it out here.\nFeel free to reach out to me with any ideas, or if you\u0026rsquo;d also like to share your lab.\nI hope you find it helpful in your journey if you decide to build one yourself. For those of you reading that may be starting out, I wish you the best of luck!\nLearn More If you\u0026rsquo;d like to learn more about homelabbing, check out the homelab community on Reddit as well as their introductory wiki.\nAlso check out r/selfhosted for any ideas on the services you can host, and awesome-selfhosted for a complete and curated list.\n","permalink":"https://netsparse.dev/posts/2023-02/why-a-homelab/","summary":"A homelab is a place where you can experiment, learn, and grow in ways you never thought possible. You can build yourself an environment to test and tinker with some technologies you may be interested in, practice setting up networks and operating systems, and explore cutting-edge technologies.\nWith a homelab, you\u0026rsquo;re not just reading about the technology - you\u0026rsquo;re experiencing it firsthand. It\u0026rsquo;s a space where you can make mistakes and learn from them, without the fear of potentially damaging a production environment.","title":"Why a Homelab?"},{"content":"H1DC and H2DC are projects I\u0026rsquo;ve been actively working on long before starting this site. Both labs are meant to be a testing platform for me in learning new technologies. I\u0026rsquo;ve been able to build them throughout the past 4 years, although they have been in constant flux, I believe these labs have definitely influenced my journey and development as an IT professional, and continue to influence my learning everyday.\nHomelab #1 \u0026ldquo;H1DC\u0026rdquo; Logical Layout Physical Layout The first home lab titled \u0026ldquo;H1DC\u0026rdquo; (\u0026ldquo;DC\u0026rdquo; short for Datacenter), was actually my first lab, it is at my family\u0026rsquo;s residence, but I do manage it remotely if needed.\nAlthough the lab has gone through many changes over the years, the diagram above illustrates the most recent version of how the network is laid out, and the services currently hosted there.\nI\u0026rsquo;ve tried to keep things a bit logically simple, as compared to Homelab #2, as H1DC is no longer my primary lab, therefore I only host a few docker containers there.\nDevices 1 Mini Server\nRaspberry Pi 3b+ 3 Network Devices\nEdgerouter X router (as the \u0026ldquo;CORE\u0026rdquo; router) TP-Link 5 port PoE switch (as my \u0026ldquo;CORE\u0026rdquo; switch) Ubiquiti AP-AC Lite Access Point 3 IP cameras\nReolink Power Supplies\nAPC Back-UPS (BE425M) 425VA/255W Services Local:\nSMB DNS FTP VPN (through Pi-VPN, and WireGuard on Edgerouter X) Deployed using Docker:\nPortainer Nginx Proxy Manager Jellyfin Heimdall Bookstack Watchtower Uptime Kuma Pi-hole UniFi controller Speedtest-tracker Filebrowser Homelab #2 \u0026ldquo;H2DC\u0026rdquo; Logical Layout Physical Layout The second lab, titled \u0026ldquo;H2DC\u0026rdquo;, is my lab at my current residence, it has been in development since 2020.\nDevices 2 Servers\nSynology DS720+ NAS (as my \u0026ldquo;STORAGE\u0026rdquo; node) Dell Optiplex Micro 3020M (as my \u0026ldquo;COMPUTE\u0026rdquo; node) 4 Network Devices\nUbiquiti Edgerouter X (as the \u0026ldquo;CORE\u0026rdquo; router) UniFi Flex Mini (as the \u0026ldquo;CORE\u0026rdquo; switch) Netgear switch (as an \u0026ldquo;ACCESS\u0026rdquo; switch) Ubiquiti AP-AC Lite Access Point Power Supplies\n2 x APC Back-UPS Pro (BR1000MS), 1000VA/600W Sine Wave Services Local:\nSMB DNS VPN (through WireGuard via Tailscale) Active Directory (planned) Deployed using Docker:\nPortainer Nginx Proxy Manager Jellyfin Tailscale Heimdall Watchtower Uptime Kuma Pi-hole UniFi controller Speedtest-tracker Filebrowser Bookstack Mealie Kiwix Navidrome \u0026amp; more\u0026hellip;\nThe physical layout in my opinion is not very sophisticated, all the lab devices are actually housed in my TV stand in the living room as you can see below:\nThe devices are not entirely enclosed as there is an inlet in the back of the TV stand, which allows some airflow to and from the devices.\nYou can also see where my UPS is located:\nI have 2 of these APC UPS devices, one in the living room and the other in my office/bedroom.\nPower Utilization Both UPS devices are 1000VA/600W.\nThe one in the living room can run for about 1hr 30min at 37-40W in the event of a power outage.\nIn Summary The home lab projects have been an invaluable learning experience.\nI hope to continue my learning through the use of these labs, as they have definitely been a great learning experience and hobby.\n","permalink":"https://netsparse.dev/posts/2023-01/lab-overview/","summary":"H1DC and H2DC are projects I\u0026rsquo;ve been actively working on long before starting this site. Both labs are meant to be a testing platform for me in learning new technologies. I\u0026rsquo;ve been able to build them throughout the past 4 years, although they have been in constant flux, I believe these labs have definitely influenced my journey and development as an IT professional, and continue to influence my learning everyday.","title":"2023 Lab Overview"},{"content":"So it\u0026rsquo;s been quite the journey figuring out the ins \u0026amp; outs of setting up a blog and writing posts in markdown. So I figured I may as well write about it.\nComing briefly from writing posts on Wordpress, I wanted to take on the challenge in learning how to use Git, treating the setup of this site as code, and jumping into a bit of CI/CD when it comes to deploying some of the changes to this site, as it is currently now hosted on Netlify.\nPrevious Iteration of this Site Previously, I was testing the waters with running Wordpress in a docker container on a AWS EC2 instance.\nAmazon\u0026rsquo;s free-tier program lets me run 1 instance for free, for 12-months, so long as I don\u0026rsquo;t exceed any bandwidth, disk usage, and so forth.\nI liked the idea and the setup was a bit straightforward for me, as I was already familiar with docker and running services in my homelab for quite some time now.\nAfter setting up the site and launching it, I began seeing many attempts to login to the /wp-admin site.\nI read that this is usually a common thing with internet facing sites, but was able to mitigate it by adding some WAF rules in Cloudflare.\nAll worked fine and the brute force attempts went away.\nI let the host run for about 3 months, just to see how it dealt with any inbound bots and whatnot, and it actually did quite well.\nSlowdown As I started posting, adding some testing material and so forth, I began to notice Wordpress slowing down (differences in speed and also when loading any other webpages). This was minimal at first but began to incrementally get worse over time.\nGiven that Wordpress was running as a lightweight docker container, I do think I was pushing the EC2 instance quite a bit once I started adding and changing the content, and also adding more containers.\nI started experimenting with hosting the blog separately on the same machine as a separate docker container running Ghost. I believe this is when I started to see the slow down a lot more.\nI want to be honest and say that this is likely not best practice as I had no load-balancing or any redundancy whatsoever, although I do think it makes for an invaluable learning experience.\nAs I managed the new site and worked my way through learning AWS, I kind of wanted to push it a bit further to see what this little instance could handle, so I setup a separate container running Matomo for analytics. I knew there was an add-on for Wordpress but wanted to try the full suite on its own.\nAnd voila! It kept running!\nAfter the fun and experimentation, and after learning and realizing that the tiny machine on the cloud could keep up (with minimal traffic of course, since any substantial increase would otherwise trample it), I had to eventually move on to something more robust, simpler, and possibly cooler to manage. And that is where I ended up here.\nStatic Site Generators For those of you that may be new to SSGs (like me), they\u0026rsquo;re essentially a way to automate the creation (or generation) of full static HTML webpages using templates, without needing to fully code the HTML from scratch.\nYou can find a good explanation from Cloudflare here.\nI had several options I could choose from initially, I was mixed between going with some of the popular ones like Hugo, Jekyll, 11ty and a few others.\nI have also wanted to learn Git for quite some time now, so I figured this would be a good opportunity to give it a shot.\nAlthough I\u0026rsquo;ve managed to setup and experiment with both Hugo and Jekyll, I decided to stick with Jekyll for now since I had pretty much set up this site on Jekyll, plus I liked the minimal theme of this site.\nThough I may plan on moving this blog into Hugo in the future!\nUPDATE: This blog has now been successfully transferred to Hugo as of April 2023.\nWhat now? The goal of this site is not only to document my learning, but also, to share it.\nAny content here is both for my reference, but also for you, any value you get out of it is both a win/win.\nAnyone out there that is also on their journey in IT, or any career in tech, I wish you the best, and good luck!\nThanks again for reading!\n","permalink":"https://netsparse.dev/posts/2023-01/journey/","summary":"\u003cp\u003eSo it\u0026rsquo;s been quite the journey figuring out the ins \u0026amp; outs of setting up a blog and writing posts in markdown.\nSo I figured I may as well write about it.\u003c/p\u003e","title":"Starting This Site"},{"content":"I’ve had a huge interest in computers, the internet, building things, and learning, since I was a kid.\nHaving grown up with limited access to the web, I was always astounded by computers, what they could do, and also what we could do with them.\nWhen I became older, and got my first personal laptop, a whole new world was introduced to me, and that was when I knew I wanted to take on the challenge of learning the magic behind the system.\nBackground I’ve worked in the IT industry since 2018, in positions ranging from Geek Squad Agent to Network Specialist for a large ISP.\nIn May 2022, I completed my Associates of Applied Science (AAS) in LAN Systems/Network Administration from Austin Community College.\nCurrently, I am pursuing the Cisco CCNA, along with Security+ and Linux+ certifications, with the goal of completing the CCNA by the end of 2023, and the other two by mid-2024.\nI find that my strengths are in enterprise networking, virtualization, cybersecurity, and DevOps, with plenty more that I continue to learn everyday.\nWhy? I started this site to document my journey, and share what I’ve learned throughout school and on my own, with anyone that may also be pursuing a similar path (or is simply just a curious soul like me). As I’ve kept pushing through, I believe many of us eventually come to realize.. We never stop learning.\nNormally, I’m accustomed to learning about networks and Linux, I’ve recently taken a dive into the world of web development, hosting websites and web apps. I’ve had a bit of experience using things like Docker to host services in my home lab, so this serves me as a potential learning opportunity to expand my existing skillsets and possibly be of help for people on that same journey.\nHobbies When I am not spinning up new virtual machines, fixing up my home lab, writing a blog post, or performing some kind of troubleshooting, you can usually find me outdoors hiking around the many trails in Austin, along with occasional kayaking, cruising in or around the city, and jamming out to some epic tunes.\nOther hobbies of mine include playing the piano, guitar and ocassionally some drums, along with a multitude of other things.\nFeel free to reach out to me anytime.\nThanks for checking out my site!\n","permalink":"https://netsparse.dev/about/","summary":"I’ve had a huge interest in computers, the internet, building things, and learning, since I was a kid.\nHaving grown up with limited access to the web, I was always astounded by computers, what they could do, and also what we could do with them.\nWhen I became older, and got my first personal laptop, a whole new world was introduced to me, and that was when I knew I wanted to take on the challenge of learning the magic behind the system.","title":"About"},{"content":"You can connect with me through the channels below, feel free to reach out regarding any questions or ideas you may have, I\u0026rsquo;d love to hear!\nLinkedIn in/netsparse\nEmail contact[at]netsparse.dev\n","permalink":"https://netsparse.dev/contact/","summary":"You can connect with me through the channels below, feel free to reach out regarding any questions or ideas you may have, I\u0026rsquo;d love to hear!\nLinkedIn in/netsparse\nEmail contact[at]netsparse.dev","title":"Contact"},{"content":"2023 Future Full Lab Orchestration with Kubernetes Current Improvements in Backup \u0026amp; Recovery Strategies Local Services Performance fine-tuning Automating Lab with Ansible Home Lab Documentation Website \u0026amp; Blog Revisions Completed Migrated Jekyll Site to Hugo - Apr 2023 Web Calc with Python and Flask - Feb 2023 Website \u0026amp; Reference Blog launched - Jan 2023 2022 The projects below are a general overview of some of the major projects I was able to complete over the course of the year, no detailed documentation exists as things were constantly evolving, although I may write about some of the techniques and setup guides in a future post.\nProxmox server deployment (H2DC) Migrated most applications to Docker (both) Restructuring of H2DC network 2021 Whole-network UPS upgrade (H2DC) Restructuring of H1DC Network First test runs of Docker on H1DC Lab 2020 Initial lab designs (both) H2DC Lab Deployed New Synology NAS (H2DC) 2019 H1DC Lab Deployed Homelab begins ","permalink":"https://netsparse.dev/projects/","summary":"2023 Future Full Lab Orchestration with Kubernetes Current Improvements in Backup \u0026amp; Recovery Strategies Local Services Performance fine-tuning Automating Lab with Ansible Home Lab Documentation Website \u0026amp; Blog Revisions Completed Migrated Jekyll Site to Hugo - Apr 2023 Web Calc with Python and Flask - Feb 2023 Website \u0026amp; Reference Blog launched - Jan 2023 2022 The projects below are a general overview of some of the major projects I was able to complete over the course of the year, no detailed documentation exists as things were constantly evolving, although I may write about some of the techniques and setup guides in a future post.","title":"Projects"}]